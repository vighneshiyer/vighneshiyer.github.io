<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Vighnesh Iyer's Qualifying Exam - TidalSim: Multi-Level Microarchitectural Simulation and Applications in Verification</title>
    <meta name="description" content="A Unified Microarchitectural Simulation Framework to Identify and Leverage Unique Aspects of Workloads on Heterogeneous SoCs for Power and Performance Estimation and Verification">
    <meta name="author" content="Vighnesh Iyer">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <style>
.reveal h2 {
  margin-top: 1rem !important;
}
.comparison_table {
  width: 100%;
  font-size: 60%;
  border-collapse: separate !important;
  thead > tr > th:first-child {
    border-right: 2px solid #222222;
  }
  tbody > tr > td:first-child {
    border-right: 2px solid #222222;
  }
}
</style>
    <script type="module" crossorigin src="/assets/2024_01-quals-tidalsim-B9LbXfbt.js"></script>
    <link rel="modulepreload" crossorigin href="/assets/reveal.esm-B9mjqvxU.js">
    <link rel="stylesheet" crossorigin href="/assets/reveal-BKmkijhR.css">
    <link rel="stylesheet" crossorigin href="/assets/remark-ish-CoR5o79D.css">
  </head>

  <body vocab="http://schema.org/" typeof="PresentationDigitalDocument">
    <span property="publisher" style="display: none;">UC Berkeley (Jan 2024)</span>
    <time pubdate property="datePublished" datetime="2023-12-29" style="display: none;">December 29, 2023</time>
    <div class="reveal">
        <div class="slides">
            <section class="center">
  <h1>TidalSim: A Unified Microarchitectural Simulation Framework</h1>
  <h2 style="font-weight: 400;">To Identify and Leverage <strong>Unique Aspects of Workloads</strong> on <strong>Heterogeneous SoCs</strong> for Performance Estimation and Verification</h2>
  <h3 style="font-weight: 500;">Vighnesh Iyer</h3>
  <h3 style="font-weight: normal;">Qualifying Exam Presentation</h3>
  <h4 style="font-weight: normal;">Wednesday, January 17th, 2024</h4>
</section>

<section>
  <h2>Talk Outline</h2>
  <ol>
    <li class="fragment"><strong>Why</strong>: What is the problem I'm solving?</li>
    <li class="fragment"><strong>What</strong>: What is the thing I want to build?</li>
    <li class="fragment"><strong>Prior work</strong> + <strong>what's new</strong> about my proposal?</li>
    <li class="fragment"><strong>How (pt 1)</strong>: A prototype implementation of my proposal</li>
    <hr class="fragment">
    <li class="fragment"><strong>Case studies</strong> / <strong>applications</strong>: Using TidalSim for performance optimization and verification</li>
    <!--How will we use what we built to do something that was impossible before?</li>-->
    <li class="fragment"><strong>How (pt 2)</strong>: New contributions to sampled simulation methodology</li>
    <li class="fragment"><strong>Thesis outline</strong><!-- and paper plan --></li>
  </ol>
</section>

<section>
<section class="center">
  <h2 class="center">1. Why: What Is the Problem?</h2>
  <ul>
    <!--<li class="fragment">Emergence of domain-specialized heterogeneous SoCs with specialized cores and accelerators</li>
    <li class="fragment">Rapid design iteration is the key to achiving optimal PPA + time to market</li>
    <li class="fragment">Existing pre-silicon performance evaluation techniques on real workloads either bottleneck the iteration latency of the design cycle or are inaccurate</li>
    -->

    <!--<li class="fragment">Existing pre-silicon evaluation (power, performance, functionality) techniques on real workloads are unsuitable for rapid iteration</li>-->
  </ul>
</section>


<section>
  <h2 style="font-size:1.8rem;">The New-Era of Domain-Specialized Heterogeneous SoCs</h2>
  <!-- Raptor Lake, Apple M3, Snapdragon 8 Gen 3, Exynos 2200 -->
  <!-- Server class, laptop class, smartphone class - similar heterogeneous convergence -->

  <div class="r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="100%" src="/assets/raptor_lake-CFx1GjL4.jpg">
      <figcaption class="small center"><a href="https://twitter.com/Locuza_/status/1574892888491790336">Locuza (Twitter): Raptor Lake-S Die Analysis</a></figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/exynos_2200-B8cnYLX-.jpg">
      <figcaption class="small center"><a href="https://locuza.substack.com/p/die-analysis-samsung-exynos-2200">Locuza Substack: Die analysis: Samsung Exynos 2200 with RDNA2 graphics</a></figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/a17_pro-C9bk_4CF.jpg">
      <figcaption class="small center"><a href="https://twitter.com/Frederic_Orange/status/1711432628908253520/photo/1">@Frederic_Orange Twitter: A17 Pro Die Analysis</a></figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="40%" src="/assets/m3_max-RIElXPPC.jpg">
      <figcaption class="small center"><a href="https://twitter.com/highyieldYT/status/1719306863341113349/photo/1">@highyieldYT Twitter: M3 Max Die Analysis</a></figcaption>
    </div>
    <div class="fragment fade-in">
      <ul>
        <li class="fragment">Two trends in SoC design:
          <ul>
            <li>Heterogeneous cores targeting different power/perf curves + workloads</li>
            <li>Domain-specific accelerators</li>
          </ul>
        </li>
        <li class="fragment">Need a pre-silicon evaluation strategy for rapid, PPA optimal design of these units
          <ul>
            <li>Limited time per design cycle <strong>→</strong> limited time per evaluation</li>
            <li>More evaluations = more opportunities for optimization</li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</section>

<section>
  <h2 style="font-size: 1.8rem;">The Microarchitectural Iteration Loop (Industry)</h2>

  <div class="container" style="grid-template-columns: 1fr 1fr;">
    <div class="fragment">
      <img src="/assets/uarch_iteration_flow_v2-B72T8u5S.svg" />
      <figcaption class="small center">An idealized iteration loop for microarchitectural design. The 'Evaluator' starts off as a performance simulator and transitions to RTL as the design is iterated.</figcaption>
    </div>
    <div>
      <img class="fragment" src="/assets/industry_flow-BzhHklKJ.svg" />
      <figcaption class="small fragment center">During RTL implementation we need performance validation against the model.</figcaption>
      <img width="70%" class="fragment" src="/assets/industry_flow2-Dg-vM5Ns.svg" />
      <figcaption class="small fragment center">Existing techniques for RTL performance validation</figcaption>
    </div>
  </div>

  <p class="center fragment">Industry needs a methodology for rapid RTL performance validation that can be used in the RTL design cycle.</p>

  <!-- <p class="center fragment">We want an "Evaluator" that has low latency, high throughput, high accuracy, low cost, and rich output collateral</p>
  <p class="center fragment"><strong>Existing tools cannot deliver on all axes</strong></p>-->

  <!-- Can't get all axes using any existing tool (low latency, high throughput, low cost, high accuracy, rich output collateral)! -->
  <!-- <p class="center fragment">Existing pre-silicon evaluation (power, performance, functionality) techniques on real workloads are unsuitable for rapid iteration</p> -->
</section>

<section>
  <h2>The Microarchitectural Iteration Loop (Academia)</h2>
  <!-- Using RTL in evaluation has been too difficult -->

  <div class="center">
      <img class="fragment" src="/assets/academic_flow-YLZmyLAb.svg" />
      <figcaption class="small center fragment">The typical manner in which microarchitectural ideas are evaluated in academia. Academics rarely write RTL due to the difficulty of evaluation, instead opting for uArch simulators.</figcaption>
  </div>

  <p class="center fragment">Academia needs a methodology for rapid RTL evaluation as a part of an RTL-first evaluation strategy</p>
</section>

<section>
  <h2>The Microarchitectural Iteration Loop (Startup)</h2>
  <!-- Must advance a RTL-first design methodology -->

  <div class="container" style="grid-template-columns: 1fr 1.5fr;">
    <div>
      <img width="70%" class="fragment" src="/assets/startup_flow1-CXIJ0dxW.svg" />
      <figcaption class="small fragment center">Startups have limited human resources to allocate to performance modeling, instead choosing to focus on architecture and RTL design.</figcaption>
    </div>
    <div>
      <img width="100%" class="fragment" src="/assets/startup_flow2-CnxyITYf.svg" />
      <figcaption class="small fragment center">Cost-constrained, lean, teams can't depend on expensive emulation/prototyping platforms.</figcaption>
    </div>
  </div>

  <p class="center fragment">Chip startups need a methodology for low-cost and rapid RTL evaluation to enable high productivity and confidence</p>
</section>

<section>
  <h2>Limitations of Existing Evaluators</h2>

  <div class="center">
    <img width="40%" src="/assets/uarch_iteration_flow_v2-B72T8u5S.svg" />
  </div>

  <ul class="small fragment">
    <li><strong>ISA simulation</strong>: no accuracy</li>
    <li><strong>Trace/Cycle uArch simulation</strong>: low accuracy <!--(unknown sources of errors)--></li>
    <li><strong>RTL simulation</strong>: low throughput</li>
    <li><strong>FPGA prototyping</strong>: high startup latency</li>
    <li><strong>HW emulators</strong>: high cost</li>
  </ul>

  <p class="center fragment">We will propose a <em>simulation methodology</em> that can deliver on all axes (accuracy, throughput, startup latency, cost) and is useful for industry, academics, and startups.</p>
</section>

<section class="center">
  <h2>Backup Slides</h2>
</section>

<section>
  <h2>The End of "Free" Technology Scaling</h2>

  <p class="center fragment"><strong>Moore's Law</strong>: transistor counts double while cost/transistor halves every 2 years</p>

  <div class="container fragment">
    <div>
      <img width="60%" src="/assets/wafer_cost_trend-BvZG_iRe.jpg" />
    </div>
    <div>
      <img width="60%" src="/assets/per_transistor_cost_trend-CDczBhMJ.png" />
    </div>
  </div>

  <ul class="small">
    <li class="fragment">Per-wafer and per-transistor costs continue to grow with process scaling<sup>[1, 2]</sup> unless heavily amortized</li>
  </ul>

  <p class="fragment center"><strong>→</strong> Transistors are no longer free</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: <a href="https://www.semianalysis.com/p/the-dark-side-of-the-semiconductor">SemiAnalysis: The Dark Side of the Semiconductor Design Renaissance</a>.<br/>
    [2]: <!-- https://www.fabricatedknowledge.com/p/the-rising-tide-of-semiconductor -->
<a href="https://filecache.investorroom.com/mr5ir_marvell/131/download/Marvell%20Investor%20Day%202020.pdf">Marvell Investor Day 2020</a>.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Stagnation of Single Thread Performance</h2>

  <p class="center fragment"><strong>Dennard Scaling</strong>: power density is constant with technology scaling</p>

  <div class="container fragment">
    <div>
      <img width="80%" src="/assets/single_thread_performance_trend-DOBOVAq9.png" />
    </div>
    <div>
      <img width="100%" src="/assets/50_years_of_microprocessor_trend_data-DggT7ewA.png" />
    </div>
  </div>

  <ul class="small">
    <li class="fragment">General-purpose single-thread performance has stagnated<sup>[1,2]</sup></li>
  </ul>

  <p class="fragment center"><strong>→</strong> Can't rely on technology scaling for gains in performance</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: <a href="https://www.doc.ic.ac.uk/~wl/teachlocal/arch/papers/cacm19golden-age.pdf">CACM: A New Golden Age for Computer Architecture</a>.<br/>
    [2]: <a href="https://github.com/karlrupp/microprocessor-trend-data">Karl Rupp; 50 Years of Microprocessor Trend Data</a>.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Trends in SoCs</h2>

  <div class="container" style="text-align: center; grid-template-columns: 1fr 1fr;">
    <div class="fragment">
      <p style="margin-top: 0;"><strong>End of Moore's Law</strong></p>
      <p style="margin-top: 0;"><strong>→</strong> $/transistor not falling</p>
      <p style="margin-top: 0;"><strong>→</strong> Transistors are no longer free</p>
      <p style="margin-top: 0; margin-bottom: 0;"><strong>→</strong> <strong>Need aggressive PPA optimization</strong></p>
    </div>
    <div class="fragment">
      <p style="margin-top: 0;"><strong>End of Dennard Scaling</strong></p>
      <p style="margin-top: 0;"><strong>→</strong> Power density <em>increasing</em></p>
      <p style="margin-top: 0;"><strong>→</strong> <em>GPP</em> performance stagnating</p>
      <p style="margin-top: 0; margin-bottom: 0;"><strong>→</strong> <strong>Need domain-specialization to not stagnate</strong></p>
    </div>
  </div>

  <hr class="fragment">

  <p class="center fragment" style="margin-top: 0.5rem; margin-bottom: 0.5rem;">Motivates two trends in SoC design</p>

  <ol>
    <li class="fragment">Heterogeneous cores
      <ul>
        <li>Cores targeting different power/performance curves</li>
        <li>Domain-specific cores</li>
        <li>Core-coupled accelerators (ISA extensions)</li>
      </ul>
    </li>
    <li class="fragment">Domain-specific accelerators</li>
  </ol>
  <!--<em>General-purpose</em> single thread performance is stagnating, but tuned cores still can squeeze a lot more out-->
</section>

<section>
  <h2>Specialized Core Microarchitectures</h2>

  <!-- Another point: Different CPUs have very different pipelines and designs based on power/perf tradeoff + workload tuning -->
  <!-- It is not just hardware parameter sweeping!!! -->
  <div class="container">
    <div>
      <img src="/assets/cortex_a77_block_diagram-cvAo0ccu.svg" />
      <figcaption class="small center"><a href="https://en.wikichip.org/wiki/arm_holdings/microarchitectures/cortex-a77">WikiChip: Cortex-A77 Microarchitecture Block Diagram</a></figcaption>
    </div>
    <div>
      <ul>
        <li class="fragment">Different CPUs in the same SoC aren't just variants of the same underlying microarchitecture
          <!--<ul>
            <li class="fragment">They have completely independent designs!</li>
            <li class="fragment">Hardware parameter space exploration is performed for a given microarchitectural blueprint</li>
            <li>
          </ul>-->
        </li>
        <li class="fragment">The broad categories of microarchitectural iteration
          <ol style="font-size: 1.2rem;">
            <li class="fragment">Creating a new structure (vector unit, prefetcher, new type of branch predictor)</li>
            <li class="fragment">Optimizing an existing structure (ROB dispatch latency, new forwarding path)</li>
            <li class="fragment">Tuning hardware parameters (cache hierarchy and sizing, LSU queue sizing)</li>
          </ol>
        </li>
        <li class="fragment">Must evaluate PPA <em>tradeoffs</em> of each modification on specific workloads</li>
        <!-- It's about tradeoffs on PPA on specific workloads! Not about optimizing some big function of HW parameters to PPA. -->
      </ul>
    </div>
  </div>
</section>

<section>
  <h2>Microarchitecture Design Challenges</h2>

  <div class="fragment" style="display: grid; place-items: center;">
    <img width="50%" src="/assets/ibs_cost_per_node_trend-DeID8dKs.webp" />
    <figcaption class="small center"><a href="https://semiengineering.com/big-trouble-at-3nm/">IBS: IC design costs growing for each node</a></figcaption>
  </div>

  <!-- Time limit! Need to spin as fast as possible during design phase and then freeze. Number of spins dictates how much performance can be squeezed out per generation! -->
  <!-- What is the challenge? pick specializations that are possible and evaluate them -->
  <!-- Optimizing real-world software pre-silicon is very hard -->

  <ul class="smallish" style="margin-top: 1rem;" >
    <li class="fragment">We want optimal designs for heterogeneous, domain-specialized, workload-tuned SoCs</li>
    <li class="fragment">Limited time to iterate on microarchitecture and <em>optimize PPA</em> on <em>real workloads</em></li>
    <li class="fragment">Time per evaluation (microarchitectural iteration loop) limits number of evaluations
    </li>
  </ul>
  <p class="center fragment">More evaluations = more opportunities for optimization</p>
</section></section>

<section>
<section class="center">
  <h2 class="center">2. What: Our Vision for TidalSim</h2>
  <p class="center fragment"><strong>What if</strong> we had a magic box that:</p>

  <ol>
    <li class="fragment">Is <strong>fast</strong> enough to run real workloads<!-- on heterogeneous SoCs--></li>
    <li class="fragment">Is <strong>accurate</strong> enough to use confidently for microarchitectural DSE</li>
    <li class="fragment">Has <strong>low latency</strong> to not bottleneck the hardware iteration loop</li>
    <li class="fragment">Can produce <strong>RTL-level collateral</strong> for performance or functional verification</li>
    <li class="fragment">Can run <strong>real workloads</strong> by identifying unique aspects of the program automatically<!--with respect to power, performance, and functionality--></li>
    </li>
  </ol>
</section>

<section>
  <h2>What: TidalSim</h2>
  <!-- How does this tool address the challenges we posed in the Why section? -->

  <div class="center">
    <img src="/assets/uarch_iteration_flow_tidalsim_simple-Dl6TUpqo.svg" />
    <figcaption class="smallish center"><strong>TidalSim</strong>: a fast, accurate, low latency, low cost microarchitectural <em>simulation methodology</em> that produces RTL-level collateral for performance estimation and verification on real workloads.</figcaption>
  </div>
</section>

<section>
  <h2>TidalSim Components</h2>

  <div class="center fragment">
    <img src="/assets/tidalsim_components_simple-CbbcfebR.svg" />
    <figcaption class="fragment small center">Overview of the components of TidalSim.</figcaption>
  </div>

  <p class="center fragment">TidalSim is <em>not</em> a simulator. It is a <em>simulation methodology</em> that combines the strengths of architectural simulators, uArch models, and RTL simulators.</p>
</section>

<section>
  <h2>TidalSim Execution</h2>

  <div class="center fragment">
    <img width="70%" src="/assets/tidalsim_time_domain-C2xoJwkB.svg" style="margin-top:-1rem;"/>
    <figcaption class="fragment smallish center" style="margin-top:-1.5rem;">TidalSim moves simulation execution back and forth between architectural, uArch, and RTL simulators based on dynamic workload analysis.</figcaption>
  </div>
</section>

<!-- What does TidalSim **enable** (for each of the people - industry, academia, startups) -->
<section>
  <h2>What Does TidalSim Enable?</h2>

  <div class="r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center; width: 80%;">
      <h3 class="center">Industry</h3>
      <img src="/assets/industry_flow2-Dg-vM5Ns.svg" height="100%" />
      <figcaption style="margin-top: 1rem;" class="center">RTL performance validation is too costly.</figcaption>
    </div>

    <div class="fragment fade-in-then-out" style="display: grid; place-items: center; width: 80%;">
      <h3 class="center">Industry</h3>
      <img src="/assets/industry_flow_new-D1Ki6LJy.svg" height="100%" />
      <figcaption style="margin-top: 1rem;" class="center">Rapid RTL performance validation becomes viable.</figcaption>
    </div>

    <div class="fragment fade-in-then-out" style="display: grid; place-items: center; width: 80%;">
      <h3 class="center">Academia</h3>
      <img src="/assets/academic_flow-YLZmyLAb.svg" height="100%" />
      <figcaption style="margin-top: 1rem;" class="center">Academics resort to inaccurate uArch simulators.</figcaption>
    </div>

    <div class="fragment fade-in-then-out" style="display: grid; place-items: center; width: 80%;">
      <h3 class="center">Academia</h3>
      <img src="/assets/academic_flow_new-B2F_2maf.svg" height="100%" />
      <figcaption style="margin-top: 1rem;">RTL-first evaluation strategy becomes viable.</figcaption>
    </div>

    <div class="fragment fade-in-then-out" style="display: grid; place-items: center; width: 80%;">
      <h3 class="center">Startup / Lean Team</h3>
      <img src="/assets/startup_flow2-CnxyITYf.svg" height="100%" />
      <figcaption style="margin-top: 1rem;">No rapid performance evaluation strategy for RTL.</figcaption>
    </div>

    <div class="fragment fade-in" style="display: grid; place-items: center; width: 80%;">
      <h3 class="center">Startup / Lean Team</h3>
      <img src="/assets/startup_flow_new-BXwzwXxW.svg" height="100%" />
      <figcaption style="margin-top: 1rem;">RTL-first design strategy becomes viable.</figcaption>
    </div>
  </div>

  <p class="fragment center">TidalSim <strong>enables new design methodologies</strong> for industry, academia, and lean chip design teams.</p>
</section>

<section>
  <h2>Scope of Thesis</h2>

  <div class="container">
    <div>
      <img width="100%" src="/assets/tidalsim_components_simple-CbbcfebR.svg" />
    </div>
    <div>
      <img width="100%" src="/assets/uarch_iteration_flow_tidalsim_simple-Dl6TUpqo.svg" />
    </div>
  </div>

  <ol>
    <li class="fragment">Implementation of TidalSim</li>
    <li class="fragment">Evaluation of TidalSim for performance estimation on realistic and large workloads
      <ul style="font-size: 1.4rem;">
        <li>Embench, SPEC, HyperProtoBench, HyperCompressBench</li>
      </ul>
    </li>
    <li class="fragment">Case studies for hardware DSE and coverpoint synthesis</li>
  </ol>
</section></section>

<section>
<section class="center">
  <h2 class="center">3. Background and Prior Work</h2>
  <ul>
    <li class="fragment">An overview of simulation broadly
      <ul><li>Abstractions used in hardware modeling</li></ul>
    </li>
    <li class="fragment">Comparison of existing pre-silicon simulation techniques</li>
    <li class="fragment">The limitations of microarchitectural simulators</li>
    <li class="fragment">Sampled simulation
      <ul>
        <li>SimPoint: Representative sampling + phase behavior of programs</li> <!-- interval embedding + clustering -->
        <li>SMARTs: Random sampling</li> <!-- error bounding via CLT -->
        <li>Functional warmup techniques</li>
      </ul>
    </li>
    <li class="fragment">Why RTL-level sampled simulation?</li>
    <!--<li class="fragment">Prior work on rapid microarchitectural evaluation</li>-->
  </ul>
</section>

<section>
  <h2>Hardware Abstractions</h2>

  <ol class="small">
    <li class="fragment">Architectural (functional) models
      <ul>
        <li class="fragment">Emulate an ISA; they only model <em>architectural</em> state, <em>not</em> uArch state</li>
        <li class="fragment"><strong>Examples</strong>: spike (RISC-V), qemu (multiple ISAs)</li>
      </ul>
    </li>
    <li class="fragment">Microarchitectural models (<em>"rough"</em>) with approximate state and timing
      <ul>
        <li class="fragment"><strong>Inputs</strong>: High-level microarchitectural description, workload characteristics
        <li class="fragment"><strong>Outputs</strong>: Performance estimate (e.g. aggregate IPC)</li>
        <li class="fragment"><strong>Example</strong>: McPAT</li>
      </ul>
    </li>
    <li class="fragment">Microarchitectural models (<em>"detailed"</em>) with more refined state and timing
      <ul>
        <li class="fragment"><strong>Inputs</strong>: Detailed microarchitectural description, ELF binary</li>
        <li class="fragment"><strong>Outputs</strong>: Detailed pipeline execution trace + low-level performance metrics</li>
        <li class="fragment"><strong>Examples</strong>: gem5, ZSim, SST, MARSSx85, Sniper, ESESC</li>
      </ul>
    </li>
    <li class="fragment">Register-transfer level (RTL) models with full fidelity state and timing
      <ul>
        <li class="fragment"><strong>Examples</strong>: Verilog, Chisel</li>
      </ul>
    </li>
  </ol>

  <hr class="fragment">

  <p class="center fragment">Each abstraction makes an accuracy / latency / throughput tradeoff.</p>
</section>

<section>
  <h2>Simulator Metrics</h2>

  <p class="center fragment">Simulation techniques span the gamut on various axes. Each simulation technique assumes <em>a particular hardware abstraction</em>.</p>

  <ul class="smallish">
    <li class="fragment"><strong>Throughput</strong>
      <ul><li>How many instructions can be simulated per real second? (MIPS = millions of instructions per second)</li></ul>
    </li>
    <li class="fragment"><strong>Accuracy</strong>
      <ul><li>Do the output metrics of the simulator match those of the modeled SoC in its real environment?</li></ul>
    </li>
    <li class="fragment"><strong>Startup latency</strong>
      <ul><li>How long does it take from the moment the simulator's parameters/inputs are modified to when the first instruction is executed?</li></ul>
    </li>
    <!--<li class="fragment"><strong>Metric diversity</strong>
      <ul>
        <li>What metrics can the simulator emit?</li>
        <li>This is tied to the hardware abstraction used</li>
      </ul>
    </li>-->
    <li class="fragment"><strong>Cost</strong>
      <ul>
        <li>What hardware platform does the simulator run on?</li>
        <li>How much does it cost to run a simulation?</li>
      </ul>
    </li>
  </ul>
</section>

<section>
  <!--RTL vs detailed uArch vs arch vs high-level spec

  We will restrict our scope to architectures which already have concrete implementations.
  No need to high-level analytical analysis since we're trying to speed up iteration loop, not discover new accelerator or core architectures.
  This is a separate research direction.-->
  <h2>Existing Hardware Simulation Techniques</h2>

  <table class="comparison_table">
    <thead><tr>
      <th></th>
      <th>Examples</th>
      <th>Throughput</th>
      <th>Latency</th>
      <th>Accuracy</th>
      <!--<th>Metrics</th>-->
      <th>Cost</th>
    </tr></thead>
    <tbody>
    <!--<tr class="fragment">
      <td>Analytical Models</td>
      <td>Aladdin, Timeloop</td>
      <td class="bg-green">10-1000 MIPS</td>
      <td class="bg-green">seconds</td>
      <td class="bg-red">Wildly variable</td>
      <td>PPA estimates</td>
      <td class="bg-green">Minimal</td>
    </tr>-->
    <tr class="fragment">
      <td>Architectural Simulators</td>
      <td>spike, qemu</td>
      <td class="bg-green">10-100+ MIPS</td>
      <td class="bg-green">&lt;1 second</td>
      <td class="bg-red">None</td>
      <!--<td>Commit trace</td>-->
      <td class="bg-green">Minimal</td>
    </tr>
    <tr class="fragment">
      <td>μArch Simulators</td>
      <td>gem5, Sniper, ZSim, SST</td>
      <td class="bg-orange">100 KIPS (gem5) - 100 MIPS (Sniper)</td>
      <td class="bg-green">&lt;1 minute</td>
      <td class="bg-orange">10-50% IPC error</td>
      <!--<td>Pipeline view / IPC trace</td>-->
      <td class="bg-green">Minimal</td>
    </tr>
    <tr class="fragment">
      <td>RTL Simulators</td>
      <td>Verilator, VCS, Xcelium</td>
      <td class="bg-red">1-10 KIPS</td>
      <td class="bg-orange">2-10 minutes</td>
      <td class="bg-green">Cycle-exact</td>
      <!--<td>RTL-level traces</td>-->
      <td class="bg-green">Minimal</td>
    </tr>
    <!--<tr class="fragment">
      <td>FPGA Prototypes</td>
      <td>HAPS, Protium, ZeBu</td>
      <td class="bg-green">≈ 50 MIPS</td>
      <td class="bg-red">2-6 hours</td>
      <td class="bg-green">Cycle-exact</td>
      <td>Subset of RTL signals</td>
      <td class="bg-orange">$10k+</td>
    </tr>-->
    <tr class="fragment">
      <td>FPGA-Based Emulators</td>
      <td>Firesim</td>
      <td class="bg-green">≈ 10 MIPS</td>
      <td class="bg-red">2-6 hours</td>
      <td class="bg-green">Cycle-exact</td>
      <!--<td>Subset of RTL signals</td>-->
      <td class="bg-orange">$10k+</td>
    </tr>
    <tr class="fragment">
      <td>ASIC-Based Emulators</td>
      <td>Palladium, Veloce</td>
      <td class="bg-green">≈ 0.5-10 MIPS</td>
      <td class="bg-orange">&lt;1 hour</td>
      <td class="bg-green">Cycle-exact</td>
      <!--<td>RTL-level traces</td>-->
      <td class="bg-red">$10M+</td>
    </tr>
    <tr class="fragment">
      <td>Multi-level Sampled Simulation</td>
      <td><strong>TidalSim</strong></td>
      <td class="bg-green">10+ MIPS</td>
      <td class="bg-green">&lt;1 minute</td>
      <td class="bg-green">&lt;1% IPC error</td>
      <!--<td>Sampled RTL-level traces</td>-->
      <td class="bg-green">Minimal</td>
    </tr>
    </tbody>
  </table>
  <!-- uArch Perf Sim is nearly there! Can we improve its accuracy or improve its throughput to get us to the golden promise land? -->

  <p class="center fragment">TidalSim combines the strengths of each technique to produce a meta-simulator that achieves high throughput, low latency, high accuracy, and low cost.</p>
</section>

<section>
  <h2>Accuracy of Microarchitectural Simulators</h2>

  <!-- Want to show:
    - simulators are generally inaccurate wrt real hardware first of all
    - simulators disagree with each other a lot
    - simulators poorly model the impact of various uarch changes (pipeline width, cache size, branch predictor)
    - simulators need calibration with silicon to get decent accuracy (which is painful and doesn't prove anything about generalizability)
  -->

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-ipc2-CUeFg0w1.png" />
      <figcaption class="small center">Raw IPC errors on 64-bit workloads vs real Haswell<sup>[1]</sup>. Microarchitectural simulators have substantial errors exceeding 20%.
      </figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-branch_predictor-B0WbZPSU.png" />
      <figcaption class="small center">Impact of using a bimodal branch predictor vs the Haswell BP<sup>[1]</sup>.
      Simulators disagree with each other! The sensitivity of each simulator is wildly different!
      </figcaption>
    </div>
  </div>

  <!-- Trends aren't enough - see the sensitivity differences of these simulators! Gradients are critical! -->
  <!-- if these detailed uArch models aren't good enough wrt accuracy, then throw the rest of the less detailed ones away too! -->

  <p class="smallish fragment center">Trends aren't enough<sup>[2]</sup>. Note the sensitivity differences - gradients are critical!</p>
  <p class="smallish fragment center">uArch simulators are <strong>not accurate enough</strong> for microarchitectural evaluation.</p>

  <div>
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Akram, A. and Sawalha, L., 2019. A survey of computer architecture simulation techniques and tools. IEEE Access<br />
    [2]: Nowatzki, T., Menon, J., Ho, C.H. and Sankaralingam, K., 2015. Architectural simulators considered harmful. Micro.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Sampled Simulation</h2>

  <p class="center fragment">Instead of running the entire program in uArch simulation, run the entire program in <em>functional simulation</em> and only run <em>samples</em> in uArch simulation</p>

  <div class="fragment center">
    <img width="60%" src="/assets/sampled_simulation0-By_c7kgf.png" />
  </div>

  <p class="fragment center">The full workload is represented by a selection of <em>sampling units</em>.</p>

  <ol class="smallish">
    <li class="fragment">How should sampling units be selected?</li> <!-- sampling methodology -->
    <li class="fragment">How can we accurately estimate the performance of a sampling unit?</li> <!-- functional and detailed warmup -->
    <li class="fragment">How can we estimate errors when extrapolating from sampling units?</li> <!-- error bounding via CLT or other heuristics -->
  </ol>
</section>

<section>
  <!--<h2 style="font-size:1.8rem;">Representative Sampling using Phase Behavior of Programs</h2>-->
  <h2>Existing Sampling Techniques</h2>

  <div class="container" style="grid-template-columns: 1fr 1fr;">
  <div>
  <h4 class="center fragment">SimPoint</h4>
  <div class="fragment" style="display:grid; align-content: center; justify-items:center; grid-template-columns:1fr 1fr;">
    <img style="display:grid;" src="/assets/simpoint-gzip_phases-DMSJez3j.gif" />
    <img style="display:grid;" src="/assets/simpoint-gcc_phases-B9RmjtbA.gif" />
  </div>
  <ul class="small">
    <li class="fragment">Program execution traces aren’t random
      <ul class="fragment">
        <li>They execute the same code again-and-again</li>
        <li>Workload execution traces can be split into <strong style="text-decoration:underline;">phases</strong> that exhibit similar μArch behavior</li>
      </ul>
    </li>
    <li class="fragment">SimPoint-style representative sampling
      <ul class="fragment">
        <li>Compute an embedding for each program interval (e.g. blocks of 100M instructions)</li>
        <li>Cluster interval embeddings using k-means</li>
        <li>Choose representative intervals from each cluster as <em>sampling units</em></li>
        <!--<li>Identify basic blocks executed in a given interval (e.g. 1M instruction intervals)</li>
        <li>Embed each interval using their ‘basic block vector’</li>
        <li>Cluster intervals using k-means</li>-->
      </ul>
    </li>
    <!--<li class="fragment" data-fragment-index="6"><strong>Hypothesis</strong>: intervals with similar embeddings → similar μArch behaviors
      <ul class="fragment" data-fragment-index="7">
        <li>Only execute unique intervals in low-level RTL simulation!</li>
        <li>We can extrapolate a full workload trace from running only the sampling units in uArch simulation</li>
      </ul>
    </li>-->
  </ul>
  </div>
  <div>
    <h4 class="center fragment">SMARTS</h4>
    <img class="fragment" src="/assets/smarts-DF7IXd20.png" />
    <ul class="small">
      <li class="fragment">Rigorous statistical sampling enables computation of confidence bounds
        <ul class="fragment">
          <li>Use random sampling on a full execution trace to derive a population sample</li>
          <li>Central limit theorem provides confidence bounds</li>
        </ul>
      </li>
      <li class="fragment">SMARTS-style random sampling
        <ul class="fragment">
          <li>Pick a large number of samples to take before program execution</li>
          <li>If the sample variance is too high after simulation, then collect more sampling units</li>
          <li>Use CLT to derive a confidence bound for the aggregate performance metric</li>
        </ul>
      </li>
      <!--<li class="fragment"><strong>Prior work</strong>: "SMARTS: Accelerating Microarchitecture Simulation via Rigorous Statistical Sampling"</li>-->
      <!--<li class="fragment">Before the workload is launched, the number of sampling units is determined
        <ul>
          <li>If the sample variance is too high to achieve the target confidence bound, then more sampling units must be collected</li>
        </ul>
      </li>
      <li class="fragment">Sampling units are selected either using random, reservoir, or systematic sampling</li>
      <li class="fragment">Central limit theorem is used to derive a confidence bound around the performance metrics reported by uArch simulation of the sampling units</li>-->
    </ul>
  </div>
  </div>

  <!--<ul class="small">
    <li class="fragment">Sampled simulation only executes specific intervals (sampling units) of the full workload in detailed performance simulation
    <li class="fragment">The sampling units are chosen based on embeddings or randomly</li>
  </ul>

  <div class="fragment center">
    <img width="40%" src="./figs/multi-level-sim/sampled_simulation.png" />
  </div>

  <ul class="small">
    <li class="fragment">Functional warmup initializes the long-lived uArch state (caches, TLB, branch predictor, prefetcher) in performance simulation</li>
    <li class="fragment">Detailed warmup initializes the short-lived uArch state (pipeline, ROB, LSU)</li>
    <li class="fragment">Performance metrics are collected after detailed warmup and are assumed to be representative of the sampling unit</li>
    <li class="fragment">The sampled intervals are used to reconstruct the full IPC trace of the workload</li>
  </ul>-->
</section>

<section>
  <h2>Functional Warmup</h2>

  <p class="fragment center">The state from a sampling unit checkpoint is only <em>architectural</em> state. The <em>microarchitectural</em> state of the uArch simulator starts at the reset state!</p>

  <div class="fragment center">
    <img width="50%" src="/assets/sampled_simulation-B0qwL7gJ.png" />
  </div>

  <ul>
    <li class="fragment">We need to seed long-lived uArch state at the beginning of each sampling unit</li>
    <li class="fragment">This process is called <em>functional warmup</em></li>
  </ul>
</section>

<section>
  <h2>Importance of Functional Warmup</h2>

  <p class="center fragment">Long-lived microarchitectural state (caches, branch predictors, prefetchers, TLBs) has a substantial impact on the performance of a sampling unit</p>

  <div class="container" style="display: grid; grid-template-columns:1fr 1.4fr;">
    <figure class="fragment center" style="display: grid; align-content: center;">
      <img width="100%" src="/assets/livesim_amat_vs_warmup-nCgAT5Wh.png" />
      <figcaption class="small center">AMAT Error vs # of detailed warmup instructions <sup>[1]</sup></figcaption>
    </figure>

    <figure class="fragment center" style="display: grid; align-content: center;">
      <img width="100%" src="/assets/warmup_mpki_plots-w_A41WY6.png" />
      <figcaption class="small center">MPKI vs warmup vs sampling unit length for different branch predictors<sup>[2]</sup></figcaption>
    </figure>
  </div>

  <div class="fragment">
  <hr>
  <div class="verysmall">
  <p class="footnote">
  [1]: Hassani, Sina, et al. "LiveSim: Going live with microarchitecture simulation." HPCA 2016.<br/>
  [2]: Eeckhout, L., 2008. Sampled processor simulation: A survey. Advances in Computers. Elsevier.
  <!--[2]: Barr, Kenneth C., et al. "Accelerating multiprocessor simulation with a memory timestamp record." ISPASS 2005.</p>-->
  </div>
  </div>
</section>

<section>
  <h2>Why RTL-Level Sampled Simulation?</h2>
  <div class="container" style="grid-template-columns: 1.4fr 1fr;">
    <div class="fragment">
      <img src="/assets/why_rtl-CcG-9V1p.svg" />
    </div>
    <div>
      <ul class="smallish">
        <li class="fragment">Eliminate modeling errors
          <ul>
            <li>Remaining errors can be handled via statistical techniques</li>
          </ul>
        </li>
        <li class="fragment">No need to correlate performance model and RTL
          <ul>
            <li>Let the RTL serve as the source of truth</li>
          </ul>
        </li>
        <li class="fragment">Can produce RTL-level collateral
          <ul>
            <li>Leverage for applications in verification and power modeling</li>
          </ul>
      </ul>
    </div>
  </div>

  <p class="center fragment">This RTL-first evaluation flow is enabled by highly parameterized RTL generators and SoC design frameworks (e.g. Chipyard).</p>
</section>

<section class="center">
  <h2>Backup Slides</h2>
</section>

<section>
  <h2>A Broad View of Simulation</h2>

  <div class="center">
    <img src="/assets/simulators_broadly-D6uiIbZ9.svg" />
    <figcaption class="small center">A high-level, generic view of the input and outputs of a simulator.</figcaption>
  </div>

  <ul style="margin-top: 1rem;">
    <li class="fragment">Simulation is the workhorse of architecture evaluation</li>
    <li class="fragment">Simulation inputs can have wide variation of fidelity
      <ul>
        <li><strong>Hardware spec</strong>: high-level models to detailed microarchitecture</li>
        <li><strong>Workload</strong>: high-level algorithmic description to concrete binary</li>
      </ul>
    </li>
    <li class="fragment">The fidelity of simulation outputs tracks that of the inputs</li>
    <!--<li>Inputs: architecture specification or framework, workload
      <ul>
        <li>Specification can be high-level (blocks + instruction spec + latencies) or very detailed</li>
        <li>Workload can be high-level (memory access pattern) or fully concrete</li>
      </ul>
    </li>
    <li>Outputs: execution trace/metrics - how does the architecture execute the workload? - notion of time granularity and space granularity + PPA stuff if available </li>-->
  </ul>
</section>

<section>
  <h2>Hardware Abstractions</h2>

  <p class="center fragment">There are roughly <strong>4 levels of hardware abstractions</strong> used in architecture evaluation</p>

  <ol>
    <li class="fragment">Architectural (functional) models</li>
    <li class="fragment"><em>"Rough"</em> microarchitectural models with approximate state and timing</li>
    <li class="fragment"><em>"Detailed"</em> microarchitectural models with more refined state and timing</li>
    <li class="fragment">Register-transfer level (RTL) models with full fidelity state and timing</li>
  </ol>
</section>

<section>
  <h2>Hardware Abstractions: Architectural (Functional) Models</h2>

  <p class="fragment center">Functional simulators emulate an architecture and can execute workloads (e.g. ELF binaries).</p>
  <p class="fragment center">They only model <em>architectural</em> state, defined in an ISA specification. No <em>microarchitectural</em> state is modeled.</p>

  <ul>
    <li class="fragment">Examples
      <ul>
        <li>RISC-V: <a href="https://github.com/riscv-software-src/riscv-isa-sim">spike</a>, <a href="https://github.com/chipsalliance/dromajo">dromajo</a>, <a href="https://www.imperas.com/riscvovpsim-free-imperas-risc-v-instruction-set-simulator">Imperas riscvOVPSim</a></li>
        <li>Multi-ISA (x86, ARM, RISC-V): <a href="https://www.qemu.org/">qemu</a></li>
      </ul>
    </li>
    <li class="fragment">Very fast (10-1000 MIPS), low startup latency (instant)</li>
    <li class="fragment">Cannot estimate PPA</li>
  </ul>
</section>

<section>
  <h2>Hardware Abstractions: "Rough" uArch Models - Micro-Kernel Accelerators</h2>

  <ul class="smallish">
    <li class="fragment">Microarchitecture is modeled with high-level blocks with a dataflow and timing relationship</li>
    <li class="fragment">Prior Work: Aladdin<sup>[1]</sup> is a microarchitecture estimation and simulation tool for analyzing the PPA of potential accelertors for kernels written in C</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/aladdin_architecture-B51CZ3G3.png">
      <figcaption class="small center">System architecture assumed by Aladdin</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="70%" src="/assets/aladdin_flow-B_-DgkJK.png">
      <figcaption class="small center">Aladdin flow. Inputs: workload. Outputs: dataflow microarchitecture + PPA</figcaption>
    </div>
    <!--<div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="20%" src="./figs/quals/aladdin_simulation.png">
      <figcaption class="small center">Aladdin simulation</figcaption>
    </div>-->
  </div>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: Shao, Y.S., Reagen, B., Wei, G.Y. and Brooks, D., 2014. Aladdin: A pre-rtl, power-performance accelerator simulator enabling large design space exploration of customized architectures. ACM SIGARCH.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: "Rough" uArch Models - ML Accelerators</h2>

  <ul class="small">
    <li class="fragment">Rough uArch models are used for evaluating ML accelerator architectures, dataflows, and workload mappings</li>
    <li class="fragment">Prior Work: Timeloop<sup>[1]</sup>, Accelergy<sup>[2]</sup> provides a framework for describing accelerator microarchitecture with parameterizable blocks (PEs, scratchpads), workload mappings, and simulating workloads for PPA estimates</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/accelergy_example_arch-C3DJNuix.png" style="margin:0;">
      <figcaption class="small center">An example microarchitecture modeled by Timeloop</figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/timeloop_arch_definition-CDI9QMRh.png" style="margin:0;">
      <figcaption class="small center">Microarchitecture description schema provided by Timeloop</figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="30%" src="/assets/timeloop_workload_definition-C8JI1j9_.png" style="margin:0;">
      <figcaption class="small center">Timeloop's schema for defining workloads and their mapping</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="70%" src="/assets/timeloop_outputs-Jj6neeuu.png" style="margin:0;">
      <figcaption class="small center">Timeloop + Accelergy flow. Inputs: workload. Outputs: ML microarchitecture + PPA</figcaption>
    </div>
  </div>

  <div class="fragment">
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Parashar, A., et. al., 2019. Timeloop: A systematic approach to dnn accelerator evaluation. ISPASS.<br/>
    [2]: Wu, Y.N., Emer, J.S. and Sze, V., 2019. Accelergy: An architecture-level energy estimation methodology for accelerator designs. ICCAD.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: "Rough" uArch Models - Cores</h2>
  <!-- Wattch, CACTI, McPAT (CPU modeling) -->

  <ul class="smallish">
    <li class="fragment">Rough uArch models are also common for evaluating core microarchitectures</li>
    <li class="fragment">Prior Work: McPAT<sup>[1]</sup> models CPUs with a parameterizable out-of-order pipeline and uncore components coupled to a timing simulator. CACTI<sup>[2]</sup> models the PPA of SRAM-based caches and DRAM.</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/mcpat_flow-Bkic_pWB.png">
      <figcaption class="small center">The simulation flow provided by McPAT.</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="70%" src="/assets/mcpat_output-C6gHJokF.png">
      <figcaption class="small center">McPAT results. Inputs: workload and microarch description. Outputs: PPA</figcaption>
    </div>
  </div>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Li, S., et. al., 2009. McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures. MICRO.<br />
    [2]: Muralimanohar, et al., 2009. CACTI 6.0: A tool to model large caches. HP laboratories.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: "Detailed" uArch Models - Cores</h2>

  <!-- Modeling precise microarchitectural details usually at cycle-level time-granularity -->
  <!-- Workload type - concrete binary -->

  <ul class="smallish">
    <li class="fragment">The most popular way to evaluate core microarchitectural optimizations is with a detailed execution-driven simulator. Many microarchitectural states are modeled.</li>
    <li class="fragment">Prior Work: gem5, ZSim, SST, MARSSx86, Sniper, ESESC. These simulators model the core pipeline and uncore components with cycle-level time-granularity.</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/gem5_architecture-BvtlQh1P.png">
      <figcaption class="small center">The modular architecture of gem5.</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/gem5_kanata_pipeline_viewer-B9PvtxlA.png">
      <figcaption class="small center">Detailed per-instruction core pipeline visualization using Konata.</figcaption>
    </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: RTL</h2>

  <ul>
    <li class="fragment">Register-transfer level (RTL) (e.g. Verilog) is the lowest abstraction used in pre-silicon architecture evaluation</li>
    <li class="fragment">Every bit of state and logic is explicitly modeled. RTL is the highest fidelity hardware model.</li>
    <li class="fragment">Can extract very precise power, performance, and area metrics</li>
  </ul>
</section>

<section>
  <h2>Which Hardware Abstraction is Suitable?</h2>

  <ol class="small">
    <li>Architectural (functional) models</li>
    <li>Microarchitectural models (<em>"rough"</em>) with approximate state and timing</li>
    <li>Microarchitectural models (<em>"detailed"</em>) with more refined state and timing</li>
    <li>Register-transfer level (RTL) models with full fidelity state and timing</li>
  </ol>

  <p class="center fragment">Can't compromise on accuracy or latency to enable meaningful and fast microarchitectural iteration.</p>

  <hr class="fragment">

  <p class="center fragment"><strong>"detailed" uArch models</strong> or <strong>RTL</strong> are the only options for our performance simulator selection</p>

</section>

<section>
  <h2>Can we Use Microarchitectural Simulators?</h2>
  <!-- Consider accuracy vs speed tradeoff + implementation complexity tradeoff -->

  <!-- - cite paper on arch sims considered harmful
  Accuracy - discuss why this can't be really improved - need to resort to RTL for fidelity that we can trust (on PPA)
  Throughput - we can use sampling - let's discuss that -->

  <!-- <p class="fragment center">If we can make uArch simulators <strong>faster</strong> (10x off from functional simulators) and <strong>more accurate</strong>, then the problem is solved!</p>-->

  <ul>
    <li class="fragment">uArch simulators seem to satisfy most of our requirements
      <ul>
        <li class="fragment"><strong>Low startup latency</strong>: seconds to 1 minute</li>
        <li class="fragment"><Strong>Metrics</strong>: IPC traces
        <li class="fragment"><strong>Cost</strong>: minimal</li>
      </ul>
    </li>
    <li class="fragment">Can we adapt uArch simulators to perform better in terms of <strong>accuracy</strong> and <strong>throughput</strong>?</li>
  </ul>
</section>

<section>
  <h2>Accuracy of Microarchitectural Simulators</h2>

  <!-- Want to show:
    - simulators are generally inaccurate wrt real hardware first of all
    - simulators disagree with each other a lot
    - simulators poorly model the impact of various uarch changes (pipeline width, cache size, branch predictor)
    - simulators need calibration with silicon to get decent accuracy (which is painful and doesn't prove anything about generalizability)
  -->

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-ipc-Du36ElNo.png" />
      <figcaption class="small center">
      Comparison of estimated IPC from various uArch simulators vs real IPC from Haswell.<sup>[1]</sup>
      MAPE on MiBench: 9.5% (Sniper), 44.6% (gem5), 38.2% (PTLSim) and 47.06% (Multi2Sim).
      </figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-ipc2-CUeFg0w1.png" />
      <figcaption class="small center">Raw IPC errors on 64-bit workloads vs real Haswell<sup>[2]</sup>. Simulators not only disagree with each other, but have substantial errors exceeding 20%.
      </figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-pipeline_width-B0RSXtTc.png" />
      <figcaption class="small center">Impact of halving the pipeline width (widths of fetch, decode, issue/rename, dispatch, and commit are halved)<sup>[2]</sup>. Simulators disagree with each other.
      </figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-reduced_cache_size-X0ek4KPf.png" />
      <figcaption class="small center">Impact of halving all the cache sizes<sup>[2]</sup>. Note how MARSSx86 shows <em>increased</em> IPC for some benchmarks! Again, disagreements are substantial.
      </figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/uarch_simulator_study-branch_predictor-B0WbZPSU.png" />
      <figcaption class="small center">Impact of using a bimodal branch predictor vs the Haswell BP.<sup>[2]</sup>.
      The sensitivity of each simulator is wildly different!
      </figcaption>
    </div>
  </div>

  <!-- Trends aren't enough - see the sensitivity differences of these simulators! Gradients are critical! -->

  <p class="smallish fragment center">uArch simulators are <strong>not accurate enough</strong> for microarchitectural iteration.</p>
  <p class="smallish fragment center">Trends aren't enough. Note the sensitivity differences - gradients are critical!</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Akram, A. and Sawalha, L., 2016, October. x86 computer architecture simulators: A comparative study. ICCD.<br />
    [2]: Akram, A. and Sawalha, L., 2019. A survey of computer architecture simulation techniques and tools. IEEE Access
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Flexibility vs Accuracy Tradeoff of uArch Simulators</h2>

  <blockquote class="fragment small">
  Sniper though shows greater accuracy, is not very flexible to allow one to model new micro-architectural features compared to gem5.
  <!--Sniper does not support full-system simulation and the effect of OS for applications.
  It is best use is for x86 many-core user-mode workloads.-->
  On the other hand, gem5 and PTLsim are more flexible and can be used for studies of particular microarchitectural blocks, and full-system workloads, with gem5 being more configurable and showing higher accuracy. [1]
  </blockquote>

  <p class="center fragment">There is an unfavorable tradeoff of simulator flexibility (due to precise silicon calibration) and accuracy.</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Akram, A. and Sawalha, L., 2019. A survey of computer architecture simulation techniques and tools. IEEE Access<br/>
    </p>
  </div>
  </div>
</section>

<section>
  <h2>The Trends Myth</h2>
  <blockquote class="fragment small">
It is casually stated as, “Although specific details of the simulation are wrong, the overall trends will be correct.” <br />

Relative performance comparisons may be correct, even if there is absolute error caused by a poor assumption or bug.<sup>[1]</sup>
  </blockquote>

  <blockquote class="fragment small">
However, for this to be true, the new technique being evaluated through simulation must be insulated from or statistically uncorrelated with the source of simulation errors.

Because simulators can have significant errors, which are completely unknown, only in rare cases can we be sure this argument holds.<sup>[1]</sup>
  </blockquote>

  <p class="center fragment">
    Even accurate relative trends are not enough for microarchitectural iteration - the gradients must also be precise!
  </p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Nowatzki, T., Menon, J., Ho, C.H. and Sankaralingam, K., 2015. Architectural simulators considered harmful. IEEE Micro.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Accuracy of gem5 for RISC-V Cores</h2>
  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="40%" src="/assets/gem5_riscv_rsd_ipc-DhAR2EZN.png" />
      <figcaption class="small center">
      Cycles ratio of custom + 3 MiBench (qsort, stringsearch) baremetal binaries on RSD (OoO RV32IMF RISC-V core) vs a gem5 model matching the core microarchitecture parameters<sup>[1]</sup>.
      Up to 40% IPC error.
      </figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="40%" src="/assets/gem5_riscv_rsd_mpki-wyitZJfz.png" />
      <figcaption class="small center">
      Significant mismatches in L1 MPKI/MAKI are main contributor to error.<sup>[1]</sup>
      </figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/gem5_calibration_slide-C0pP1e9c.png" />
      <figcaption class="small center">
      The complexity and effort to 'calibrate' a uArch simulator to RTL simulation is significant.<sup>[2]</sup>
      </figcaption>
    </div>
  </div>

  <p class="fragment center">There is <strong>no evidence</strong> that uArch simulators can achieve sub 5% accuracy for microarchitectural iteration</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Chatzopoulos, O., et. al., 2021. Towards Accurate Performance Modeling of RISC-V Designs. arXiv preprint<br />
    [2]: Ta, T., Cheng, L. and Batten, C., 2018. Simulating multi-core RISC-V systems in gem5. CARRV
    </p>
  </div>
  </div>
</section>

<section>
  <h2>But Can't We Calibrate uArch Simulators?</h2>

  <!--<p class="fragment center">There is a body of work on 'calibrating' uArch simulators against silicon, but very scant work on calibrating against RTL generators</p>-->

  <ul class="smallish">
    <li class="fragment">[1] calibrates Sniper to Cortex A54 and A72 cores with average IPC errors of 7% and 15% <small>(up to 50%)</small> on SPEC CPU2017 respectively using ML to fine-tune model parameters against silicon measurements given microbenchmarks.</li>
    <li class="fragment">[2] calibrates MARSSx86 to i7-920 with post-calibration IPC error of 7% on SPEC</li>
  </ul>

  <hr class="fragment">

  <ul class="smallish">
    <li class="fragment">Absolute errors are still too high when architects must make decisions based on tiny IPC changes</li>
    <li class="fragment">Calibration only applies to a specific design point!</li>
    <li class="fragment">Gradients and errors are not understood nor bounded when microarchitecture parameters are altered to perform HW parameter DSE</li>
  </ul>

  <p class="center fragment">uArch simulators are not suitable for pre-silicon microarchitectural iteration</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Adileh, A., et al., 2019. Racing to hardware-validated simulation. ISPASS.<br />
    [2]: Asri, M., et al., 2016. Simulator calibration for accelerator-rich architecture studies. SAMOS
    </p>
  </div>
  </div>
</section>

<section>
  <h2>False Confidence from Validation</h2>

  <blockquote class="fragment small">
  A common misconception is that if the parameters are changed and configured for some other design point, the accuracy will be similar.<sup>[1]</sup>
  </blockquote>

  <blockquote class="small fragment">
  tool validation is often carried out by fitting parameters to the “specific” validation targets, not about ensuring the underlying modeling is accurate for individual phenomena or their interactions.<sup>[1]</sup>
  </blockquote>

  <p class="fragment center">Calibration / validation of a uArch simulator against silicon doesn't make it suitable for microarchitectural iteration</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Nowatzki, T., Menon, J., Ho, C.H. and Sankaralingam, K., 2015. Architectural simulators considered harmful. IEEE Micro.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Our Decision Tree Thus Far</h2>

  <!-- uArch sims are not accurate (both absolutely, wrt relative trends and gradients, and wrt parameterization). they have unbounded modeling errors that reduce our confidence substantially. -->

  <!-- We want to use RTL simulation as the lowest level performance simulator. But we also want to have enough throughput! How???-->

  <!-- While I have been hating on uArch simulators a lot, they do offer one important lesson.
  Let's learn from sampled simulation approaches previously explored by uarch simulators. -->

  <ol>
    <li class="fragment">Need high fidelity hardware abstractions <strong>→</strong> must use detailed uArch / RTL abstractions</li>
    <li class="fragment">Need high accuracy simulators but uArch simulators are not accurate
    <ul style="font-size: 1.4rem;">
      <li class="fragment">1) absolutely, 2) with regards to relative trends and gradients, and 3) with regards to parameterizations</li>
    </ul></li>
    <li class="fragment">Therefore, we must use <strong>RTL simulation</strong> as the lowest level performance simulator</li>
  </ol>

  <hr class="fragment">

  <p class="center fragment">But RTL simulation has <strong>low throughput</strong>!</p>
  <p class="center fragment">Let's take a technique from uArch simulators that improves their throughput</p>
</section>

<section>
  <h2>Random Sampling</h2>
  <ul>
    <li class="fragment"><strong>Prior work</strong>: "SMARTS: Accelerating Microarchitecture Simulation via Rigorous Statistical Sampling"</li>
    <li class="fragment">Before the workload is launched, the number of sampling units is determined
      <ul>
        <li>If the sample variance is too high to achieve the target confidence bound, then more sampling units must be collected</li>
      </ul>
    </li>
    <li class="fragment">Sampling units are selected either using random, reservoir, or systematic sampling</li>
    <li class="fragment">Central limit theorem is used to derive a confidence bound around the performance metrics reported by uArch simulation of the sampling units</li>
  </ul>
</section>

<section>
  <h2>Comparison Between Sampling Techniques</h2>

  <div class="fragment center">
    <img width="50%" src="/assets/sampled_simulation-B0qwL7gJ.png" />
  </div>

  <table class="fragment" style="font-size: 1.2rem;">
    <thead><tr>
      <th>Sampling Technique</th>
      <th>Interval Length</th>
      <th># of Intervals Simulated</th>
      <th>Interval Selection</th>
      <th>Functional Warmup</th>
      <th>Detailed Warmup</th>
      <th>Time Granularity</th>
    </tr></thead>
    <tbody>
    <tr class="fragment">
      <td><strong>SimPoint</strong></td>
      <td>10-100M</td>
      <td>50-100</td>
      <td>BBFV + k-means</td>
      <td>Optional</td>
      <td>≈0.1-1M</td>
      <td>Interval length</td>
    </tr>
    <tr class="fragment">
      <td><strong>SMARTS</strong></td>
      <td>1-10k</td>
      <td>10k</td>
      <td>Systematic sampling</td>
      <td>Required</td>
      <td>1k</td>
      <td>Entire workload</td>
    </tr>
    <tr class="fragment">
      <td><strong>TidalSim</strong></td>
      <td>10k</td>
      <td>10-100</td>
      <td>BBFV + k-means</td>
      <td>Required</td>
      <td>1k</td>
      <td>Interval Length</td>
    </tr>
    </tbody>
  </table>
</section>

<section>
  <h2>Final Takeaways</h2>

  <ul>
    <li class="fragment">Microarchitectural iteration requires high accuracy
      <ul><li><strong>→</strong> we must use <strong>RTL simulation</strong> as our performance simulator</li></ul>
    </li>
    <li class="fragment">RTL simulation has low throughput
      <ul><li><strong>→</strong> we must employ <strong>simulation sampling techniques</strong> to combine architectural and RTL simulation to improve throughput</li></ul>
    </li>
    <li class="fragment">We can't execute long sampling units in RTL simulation
      <ul><li><strong>→</strong> we must use <strong>uArch functional warmup models</strong> to minimize errors due to stale uArch state</li></ul>
    </li>
    <li class="fragment">We want <em>time-domain</em> power, performance, and RTL collateral. We want the ability to extract tiny and unique benchmarks from large workloads.
      <ul><li><strong>→</strong> we must <strong>combine the SimPoint and SMARTS</strong> sampling methodologies</li></ul>
    </li>
  </ul>
</section>
<!--
  - need high accuracy: we must use uArch/RTL as abstraction
  - uarch/RTL necessitates: we must use then uarch or rtl sim
  - uarch sim is inaccurate: we must use rtl sim
  - rtl sim is slow: so what can we do about it?
  - so we must use some kind of sampled rtl sim with functional uarch warmup models ganged with a functional isa model
--></section>

<!-- these slides have been replaced by a single slide in the background section -->
<!--<section>
</section>-->

<section>
<section class="center">
  <h2>4. How (pt 1): TidalSim v0.1<br />(A Prototype Implementation)</h2>

  <ul>
    <li>Implementation details of the TidalSim v0.1 prototype</li>
    <li>Cache functional warmup model</li>
    <li>Results for IPC trace reconstruction</li>
    <li>Going from TidalSim v0.1 to v1</li>
  </ul>
</section>

<!--
  - Program intervals
  - Basic block embedding (show example)
  - Clustering (show example of clusters we extracted, 2D SVD projection and cluster coloring)
  - Checkpointing and snapshot taking
  - Injection into RTL-level simulation
  - Performance metric extraction
  - Extrapolation
-->

<section style="text-align: center;">
  <h2>Overview of the TidalSim v0.1 Flow</h2>
  <img src="/assets/overview-_bAKuIOR.svg" />
</section>

<section>
  <h2>Implementation Details For TidalSim v0.1</h2>
  <div class="container" style="grid-template-columns: 1.2fr 1fr;">
  <div>
  <ul class="smallish">
    <li class="fragment">Basic block identification
      <ul><li>BB identification from spike commit log or from static ELF analysis</li></ul>
    </li>
    <li class="fragment">Basic block embedding of intervals</li>
    <li class="fragment">Clustering and checkpointing
      <ul>
        <li>k-means, PCA-based n-clusters</li>
        <li>spike-based checkpoints</li>
      </ul>
    </li>
    <li class="fragment">RTL simulation and performance metric extraction
      <ul><li>Custom force-based RTL state injection, out-of-band IPC measurement</li></ul>
    </li>
    <li class="fragment">Extrapolation
      <ul><li>Estimate IPC of each interval based on its embedding and distances to RTL-simulated intervals</li></ul>
    </li>
  </ul>
  </div>
  <div style="display:grid; align-content: center;">
    <img src="/assets/overview-_bAKuIOR.svg" />
  </div>
  </div>
</section>

<section>
  <h2 style="font-size: 1.8rem;">Functional Cache Warmup with Memory Timestamp Record</h2>

  <p class="smallish center fragment">Memory Timestamp Record (MTR)<sup>[1]</sup> is a cache warmup model that can be constructed once and reused for many different cache parameterizations</p>

  <div class="r-stack center smallish">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/mtr_entry_update-Cu-oXsUt.svg"/>
      <figcaption>Updating entries in the (MTR) data structure from an memory access trace</figcaption>
    </div>

    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="60%" src="/assets/mtr_reconstruction-BXVtgFdY.svg"/>
      <figcaption>Reconstructing a cache state from a MTR checkpoint for a specific cache parameterization</figcaption>
    </div>
  </div>

  <div>
    <hr>
    <div class="verysmall">
    <p class="footnote">
    [1]: Barr, Kenneth C., et al. "Accelerating multiprocessor simulation with a memory timestamp record." ISPASS 2005.</p>
    </div>
  </div>
</section>

<section>
  <h2>IPC Trace Prediction: huffbench</h2>
  <ul>
    <li class="fragment">Huffman compression from Embench (huffbench)</li>
    <li class="fragment"><code>N=10000</code>, <code>C=18</code></li>
    <li class="fragment">Full RTL sim takes 15 minutes, TidalSim runs in 10 seconds</li>
    <li class="fragment">Large IPC variance</li>
  </ul>
  <img class="fragment" src="/assets/huffbench_results-B-uR0Cp9.svg" />
</section>

<section>
  <h2>IPC Trace Prediction: wikisort</h2>
  <ul>
    <li class="fragment">Merge sort benchmark from Embench (wikisort)</li>
    <li class="fragment"><code>N=10000</code>, <code>C=18</code></li>
    <li class="fragment">Full RTL sim takes 15 minutes, TidalSim runs in 10 seconds</li>
    <li class="fragment">Can capture general trends and time-domain IPC variation</li>
  </ul>
  <img class="fragment" src="/assets/wikisort_results-KvNiNr3_.svg" />
</section>

<!-- Add box and whiskers IPC error plot -->
<section>
  <h2>Aggregate IPC Prediction for Embench Suite</h2>
  <div class="center">
    <img src="/assets/embench_ipc_error-CXDaZlnR.svg" style="margin-bottom:0;" />
  </div>
  <p class="center fragment">Typical IPC error (<strong>without</strong> functional warmup and with fine time-domain precision of 10k instructions) <strong>is &lt; 5%</strong></p>
</section>

<section class="center">
  <h2>Backup Slides</h2>
</section>

<section>
  <h2>Basic Block Identification</h2>

  <p class="center fragment">Basic blocks are extracted from the dynamic commit trace emitted by spike</p>

  <pre class="fragment"><code data-trim data-noescape>
core   0: >>>>  memchr
core   0: 0x00000000800012f6 (0x0ff5f593) andi    a1, a1, 255
core   0: 0x00000000800012fa (0x0000962a) c.add   a2, a0
core   0: 0x00000000800012fc (0x00c51463) bne     a0, a2, pc + 8
core   0: 0x0000000080001304 (0x00054783) lbu     a5, 0(a0)
core   0: 0x0000000080001308 (0xfeb78de3) beq     a5, a1, pc - 6
  </code></pre>

  <ul>
    <li class="fragment">Control flow instructions mark the end of a basic block</li>
    <li class="fragment">Previously identified basic blocks can be split if a new entry point is found</li>
    <li class="fragment"><code>0: 0x8000_12f6 ⮕ 0x8000_12fc</code></li>
    <li class="fragment"><code>1: 0x8000_1304 ⮕ 0x8000_1308</code></li>
  </ul>
</section>

<section>
  <h2>Program Intervals</h2>

  <p class="center fragment">A commit trace is captured from ISA-level simulation</p>
  <pre class="fragment text"><code data-trim data-noescape>
core   0: >>>>  memchr
---
core   0: 0x00000000800012f6 (0x0ff5f593) andi    a1, a1, 255
core   0: 0x00000000800012fa (0x0000962a) c.add   a2, a0
core   0: 0x00000000800012fc (0x00c51463) bne     a0, a2, pc + 8
---
core   0: 0x0000000080001304 (0x00054783) lbu     a5, 0(a0)
core   0: 0x0000000080001308 (0xfeb78de3) beq     a5, a1, pc - 6
core   0: 0x000000008000130c (0x00000505) c.addi  a0, 1
---
  </code></pre>
  <p class="center fragment">The trace is grouped into intervals of $ N $ instructions of which we will choose $ C $ intervals as simulation units</p>
  <p class="center fragment">Typical $C = 10-100$</p>
  <p class="center fragment">Typical $N = 10000$</p>
</section>

<section>
  <h2>Interval Embedding and Clustering</h2>

  <p class="center fragment">Each interval is embedded with a vector indicating how often each basic block was ran</p>

  <table style="width: 100%;" class="fragment small">
    <thead><tr>
      <th>Interval index</th>
      <th>Interval length</th>
      <th>Embedding</th>
    </tr></thead>
    <tbody><tr>
      <td>$ n $</td>
      <td>$ 100 $</td>
      <td>$ \begin{bmatrix}40 & 50 & 0 & 10\end{bmatrix} $</td>
    </tr>
    <tr>
      <td>$ n+1 $</td>
      <td>$ 100 $</td>
      <td>$ \begin{bmatrix}0 & 50 & 10 & 40\end{bmatrix}$</td>
    </tr>
    <tr>
      <td>$ n+2 $</td>
      <td>$ 100 $</td>
      <td>$ \begin{bmatrix}0 & 20 & 20 & 80\end{bmatrix}$</td>
    </tr>
    </tbody>
  </table>

  <ul class="small">
    <li class="fragment">Intervals are clustered using k-means clustering (typical $K = 10-30$)</li>
  </ul>
  <img class="fragment" style="margin-bottom:0;" src="/assets/aha-mont64_clustering-CeeENXIc.svg" />
  <ul class="small">
    <li class="fragment">Centroids indicate which basic blocks are traversed most frequently in each cluster</li>
    <li class="fragment">We observe that most clusters capture unique traversal patterns</li>
  </ul>
</section>

<section>
  <h2>Arch Snapshotting</h2>

  <p class="center fragment">For each cluster, take the sample that is closest to its centroid</p>
  <p class="center fragment">Capture arch checkpoints at the start of each chosen sample</p>

  <pre class="fragment"><code data-trim data-noescape>
pc = 0x0000000080000332
priv = M
fcsr = 0x0000000000000000
mtvec = 0x8000000a00006000
...
x1 = 0x000000008000024a
x2 = 0x0000000080028fa0
...
  </code></pre>

  <p class="center fragment">Arch checkpoint = arch state + raw memory contents</p>
</section>

<section>
  <h2>RTL Simulation and Arch-State Injection</h2>

  <ul>
    <li class="fragment">Arch checkpoints are run in parallel in RTL simulation for $ N $ instructions</li>
    <li class="fragment">RTL state injection caveats
      <ul>
        <li class="fragment">Not all arch state maps 1:1 with an RTL-level register</li>
        <li class="fragment">e.g. <code>fflags</code> in <code>fcsr</code> are FP exception bits from FPU μArch state</li>
        <li class="fragment">e.g. <code>FPRs</code> in Rocket are stored in recoded 65-bit format (not IEEE floats)</li>
      </ul>
    </li>
    <li class="fragment">Performance metrics extracted from RTL simulation</li>
  </ul>

  <pre class="fragment"><code data-trim data-noescape>
cycles,instret
1219,100
125,100
126,100
123,100
114,100
250,100
113,100
  </code></pre>
</section>

<section>
  <h2>Challenges with RTL-Level Sampled Simulation</h2>
  <!-- Describe the challenges, but leave the solutions for subsequent sections -->
  <!-- State injection, interval subsampling, functional warmup, performance metric extraction, supporting different microarchitectures and HW parameter spaces -->

  <ul>
    <li class="fragment">As workload traces grow to billions of dynamic instructions, $N$ will have to go up too, to avoid too many clusters
      <ul>
        <li class="fragment"><strong>→</strong> we need to perform sampling unit subsampling using SMARTS-like methodology to tolerate the low throughput of RTL simulation</li>
      </ul>
    </li>
    <li class="fragment">Functional warmup can provide us with microarchitectural state at the start of each sampling unit, but injecting that state in RTL simulation is error-prone
      <ul>
        <li class="fragment">Correlating microarchitectural cache state via RTL hierarchical paths is tricky and requires manual effort</li>
      </ul>
    </li>
    <li class="fragment">If the hardware parameterization changes (cache hierarchy/sizing, choice of branch predictor)
      <ul>
        <li class="fragment"><strong>→</strong> the functional warmup models and state injection logic must also change</li>
      </ul>
    </li>
  </ul>
</section>

<section>
  <h2>Extrapolation</h2>
  <ul>
    <li class="fragment">We gather performance metrics for one sampling unit in each cluster that is taken to be representative of that cluster ($\vec{p}$)</li>
    <li class="fragment">To compute the estimated performance of a given interval
      <ul>
        <li class="fragment">Compute the distances $\vec{d}$ of that interval's embedding to each cluster centroid</li>
        <li class="fragment">Compute a weighted mean using $\vec{d}$ and $\vec{p}$</li>
      </ul>
    <li class="fragment">Compute the estimated performance of all intervals to extrapolate to a full performance trace</li>
  </ul>
</section>

<section>
  <h2>IPC Trace Prediction: aha-mont64</h2>
  <ul>
    <li class="fragment">Montgomery multiplication from Embench (aha-mont64)</li>
    <li class="fragment"><code>N=1000</code>, <code>C=12</code></li>
    <li class="fragment">Full RTL sim takes 10 minutes, TidalSim runs in 10 seconds</li>
    <li class="fragment">IPC is correlated (mean error &lt;5%)<!--; very weak correlation between distance and error--></li>
  </ul>
  <img class="fragment" src="/assets/aha-mont64_results-DpN10JCj.svg" />
</section>

<section>
  <h2>From Tidalsim v0.1 to v1</h2>

  <!-- Things to do before calling the first prototype complete: -->

  <ul>
    <li class="fragment">Functional L1-only cache warmup</li>
    <li class="fragment">Functional branch predictor warmup</li>
    <!--<li class="fragment">Use robust checkpointing fork of spike
      <ul>
        <li>Better arch state initialization technique <span class="small">(via program snippet + selective forces depending on bits that can't be set via ISA)</span></li>
      </ul>
    </li>-->
    <li class="fragment">Characterization on other baremetal workloads
      <ul>
        <li>dhrystone, coremark, riscv-tests benchmarks, MiBench</li>
      </ul>
    </li>
    <li class="fragment">Explore more sophisticated clustering and extrapolation techniques</li>
    <li class="fragment">Demonstrate we can hit <strong>&lt;1% IPC error</strong></li>
  </ul>

  <p class="fragment center">These milestones will set the stage for the qual proposal</p>
</section></section>

<section>
<section class="center">
  <h2>5. Case Studies / Applications</h2>
  <ol style="list-style-type: lower-alpha;">
    <li class="fragment">Hardware parameter DSE / microarchitecture optimization</li>
    <li class="fragment">Coverpoint synthesis for verification</li>
  </ol>
</section>

<section>
  <h2>5.a: TidalSim for HW Parameter DSE</h2>

  <div class="center">
    <img width="80%" src="/assets/uarch_iteration_flow_tidalsim_simple-Dl6TUpqo.svg" />
  </div>

  <p class="center fragment">Demonstrate that use of TidalSim leads to better design decisions over RTL simulation and FireSim for a given compute budget.</p>

  <p class="center fragment">Show how TidalSim enables quick fine-tuning of a core for a given workload.</p>
  <!--<li class="fragment">Compare TidalSim for evaluating these tradeoffs on real workloads vs RTL simulation and FireSim</li>-->
</section>

<section>
  <h2 style="font-size: 2rem;">5.a: Microarchitectural Optimizations and Workloads</h2>

  <ul>
    <li class="fragment"><!--Evaluate the impact of cache sizing and configuration-->
      Microarchitectural knobs to explore
      <ul>
        <!--<li>Cache sizing between L1d and L1i</li>
        <li>Balancing capacity between 2-level cache hierarchies</li>
        <li>Unified vs separate I/D L2 caches</li>
        <li>Tuning cache associativity or replacement policy</li>
        <li>Branch predictor parameters (e.g. fine-tuning BTB entries)</li>-->
        <li>Prefetcher tuning<sup>[1]</sup></li>
      </ul>
    <li class="fragment">Workloads for tuning
      <ul>
        <li>HyperCompressBench (baremetal), HyperProtoBench (Linux)</li>
      </ul>
    </li>
    <li class="fragment">Expected results
      <ul>
        <li>RTL simulation <strong>→</strong> can evaluate only a few workloads, but with many design points</li>
        <li>FireSim <strong>→</strong> can evaluate many workloads, but only a few design points</li>
        <li>TidalSim <strong>→</strong> can evaluate many workloads and many design points</li>
      </ul>
    </li>
  </ul>

  <blockquote class="fragment smallish">
Many of Arm's efficiency gains come from small, microarchitectural level changes, mostly around how it implements data prefetch and branch prediction.
  </blockquote>

  <div>
    <hr>
    <div class="verysmall">
    <p class="footnote">
    [1]: <a href="https://www.anandtech.com/show/18871/arm-unveils-armv92-mobile-architecture-cortex-x4-a720-and-a520-64bit-exclusive/4">Cortex-A520: LITTLE Core with Big Improvements</a>
    </p>
    </div>
  </div>
</section>

<section>
  <h2>5.a: Leveraging HDLs for TidalSim Methodology</h2>

  <ul>
    <li class="fragment">HW DSE with TidalSim requires an RTL injection harness</li>
    <!--Existing harness is hardcoded for one Chipyard SoC design point</li>-->
    <li class="fragment">Automatic harness generation using high-level HDLs
      <ul>
        <li class="fragment">Chisel API to <em>semantically mark</em> arch and uArch state</li>
        <li class="fragment">FIRRTL pass to generate a state-injecting test harness</li>
      </ul>
    </li>
  </ul>

  <pre class="fragment"><code class="language-scala" data-trim data-noescape data-line-numbers="|3">
class RegFile(n: Int, w: Int, zero: Boolean = false) {
  val rf = Mem(n, UInt(w.W))
  (0 until n).map { archStateAnnotation(rf(n), Riscv.I.GPR(n)) }
  // ...
}
  </code></pre>

  <pre class="fragment"><code class="language-scala" data-trim data-noescape data-line-numbers="|4-6|5">
class L1MetadataArray[T &lt;: L1Metadata] extends L1HellaCacheModule()(p) {
  // ...
  val tag_array = SyncReadMem(nSets, Vec(nWays, UInt(metabits.W)))
  (0 until nSets).zip((0 until nWays)).map { case (set, way) =&gt;
    uArchStateAnnotation(tag_array.read(set)(way), Uarch.L1.tag(set, way, cacheType=I))
  }
}
  </code></pre>
</section>

<section>
  <h2>5.b: TidalSim for Verification</h2>

  <div class="container" style="grid-template-columns: 1fr 1.4fr">
    <div class="fragment">
      <img width="100%" src="/assets/uarch_iteration_flow_tidalsim_simple-Dl6TUpqo.svg" />
    </div>
    <div class="fragment">
      <img width="100%" src="/assets/cp_synthesis1-t7yDgyqW.svg" />
    </div>
  </div>

  <div class="center">

  <ul>
    <li class="fragment">Property synthesis techniques require waveforms for analysis
      <ul>
        <li><strong>Specification mining</strong> for invariant synthesis or RTL bug localization</li>
        <li><strong>Coverpoint synthesis</strong> for tuning stimulus generators towards bugs</li>
      </ul>
    </li>
  </ul>

  <p class="center fragment">TidalSim provides a way to extract many small, unique, RTL waveforms from large workloads with low latency</p>
</section>

<section>
  <h2>5.b: Past Work on Specification Mining</h2>

  <ul>
    <li class="fragment">Take waveforms from RTL simulation and attempt to mine unfalsified specifications involving 2+ RTL signals<sup>[1]</sup></li>
  </ul>

  <div class="center fragment">
    <img width="50%" src="/assets/spec_mining_flow-CLdlCYq9.svg" />
  </div>

  <ul>
    <li class="fragment">Specifications are constructed from LTL templates
      <ul>
        <li class="fragment"><strong>Until</strong>: $ \mathbf{G}\, (a \rightarrow \mathbf{X}\, (a\, \mathbf{U}\, b)) $</li>
        <li class="fragment"><strong>Next</strong>: $ \mathbf{G}\, (a \rightarrow \mathbf{X}\, b) $</li>
        <li class="fragment"><strong>Eventual</strong>: $ \mathbf{G}\, (a \rightarrow \mathbf{X F}\, b) $</li>
        <li class="fragment">$a$ and $b$ are atomic propositions constructed from signals in the RTL design</li>
      </ul>
    </li>
  </ul>

  <div>
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: Iyer, Vighnesh, et. al., 2019. RTL bug localization through LTL specification mining. MEMOCODE.
    </p>
  </div>
  </div>
</section>

<section>
  <h2 style="font-size:1.8rem;">5.b: Specification Mining Used for RTL Bug Localization</h2>

    <p class="fragment center small">Introduce a bug in the riscv-mini cache</p>

  <pre class="fragment"><code class="language-diff" data-trim data-noescape>
-  hit := v(idx_reg) && rmeta.tag === tag_reg
+  hit := v(idx_reg) && rmeta.tag =/= tag_reg
  </code></pre>

  <ul class="small">
    <li class="fragment">This bug does not affect most ISA tests but a multiply benchmark failed by hanging</li>
    <li class="fragment">Checking the VCD against the mined properties gives these violations</li>
  </ul>

  <table class="fragment" style="font-size: 1.2rem;">
    <thead><tr>
      <th>Template</th>
      <th>$\textbf{a}$</th>
      <th>$\textbf{b}$</th>
      <th>Violated at Time</th>
    </tr></thead>
    <tbody>
    <tr>
      <td>Until</td>
      <td><code>Tile.arb_io_dcache_r_ready</code></td>
      <td><code>Tile.dcache.hit</code></td>
      <td>418</td>
    </tr>
    <tr>
      <td>Until</td>
      <td><code>Tile.dcache_io_nasti_r_valid</code></td>
      <td><code>Tile.dcache.hit</code></td>
      <td>418<td>
    </tr>
    <tr>
      <td>Until</td>
      <td><code>Tile.dcache.is_alloc</code></td>
      <td><code>Tile.dcache.hit</code></td>
      <td>418</td>
    </tr>
    <tr>
      <td>Until</td>
      <td><code>Tile.arb.io_dcache_ar_ready</code></td>
      <td><code>Tile.arb_io_nasti_r_ready</code></td>
      <td>640</td>
    </tr>
    </tbody>
  </table>

  <p class="center fragment small">The violated properties point to an anomaly with the <code>hit</code> signal and localize the bug</p>
</section>

<section>
  <h2 style="font-size:1.8rem;">5.b: Coverpoint Synthesis as Complement of Spec Mining</h2>

  <div class="center fragment">
    <img width="60%" src="/assets/cp_synthesis2-CKnDjx9W.svg" />
  </div>

  <ul class="small">
    <!--<li class="fragment"><em>Specification mining</em> takes waveforms of an RTL design and synthesizes properties that are unfalsified on all traces</li>-->
    <li class="fragment">Coverpoint synthesis is an alternative take on spec mining where we synthesize μArch properties that we want to see more of
      <ul>
        <li>Instead of monitoring properties just for falsification, we also monitor them for <em>completion</em></li>
        <li>Properties that are <em>falsified</em> or <em>completed</em>, but not too often, are good candidates for coverpoints</li>
      </ul>
    </li>
    <!--<li class="fragment">This technique is far more effective if we have <em>many unique, realistic traces</em>
      <ul>
        <li class="fragment">Leverage interval clustering and sampled RTL simulation</li>
      </ul>
    </li>
    -->
    <li class="fragment">Evaluation
      <ul>
        <li class="fragment">Synthesize coverpoints on Rocket using waveforms from TidalSim and regular RTL sim with the same compute budget</li>
        <li class="fragment">Demonstrate we can synthesize more, and more interesting coverpoints using TidalSim data</li>
        <li class="fragment">Evaluate off-the-shelf RISC-V instgen on synthesized coverpoints vs structural coverage</li>
      </ul>
    </li>
  </ul>
</section>

<!-- <section>
  <h2>Performance and Power Evaluation</h2>
  <ul>
    <li class="fragment">Trace extraction for power model construction
    <ul>
      <li>Currently power macromodels are built + trained only on workloads that can run in RTL simulation</li>
      <li>TidalSim enables extraction of unique, short traces from full workloads</li>
      <li>Potential to improve signal selection and uncover holes in training datasets</li>
    </ul>
    </li>
  </ul>
</section>
-->

<!--
<section>
  <h2>Issues with HW Fuzzer Evaluations</h2>
  <ul>
    <li class="fragment"><em>Last time</em>: discussed deficiencies in existing HW fuzzing evaluations due to bad success/feedback metrics
    <ul>
      <li class="fragment">Structural coverage is too easy to hit</li>
      <li class="fragment">Time to rediscover old bugs is too biased and forces us to use old RTL</li>
    </ul>
    </li>
    <li class="fragment">Bad metrics ⮕ dubious conclusions
    <ul>
      <li>We should save &gt;50% of mutated stimuli (vs &lt;1% for SW fuzzers)</li>
      <li>RTL-level feedback is useless for hitting bugs or improving coverage (vs SW fuzzers making no progress without feedback)</li>
    </ul>
    </li>
  </ul>
  <p class="center fragment">Can we synthesize metrics that lead to reasonable HW fuzzer evaluations?</p>
</section>
-->

<!--
<section>
  <h2>Coverpoint Synthesis</h2>
  <ul>
    <li class="fragment"><em>Specification mining</em> takes waveforms of an RTL design and synthesizes properties involving 2+ signals that are unfalsified on all traces</li>
    <li class="fragment">Coverpoint synthesis is an alternative take on spec mining where we synthesize μArch properties that we want to see more of</li>
    <li class="fragment">This technique is far more effective if we have <em>many unique, realistic traces</em>
      <ul>
        <li class="fragment">Leverage interval clustering and sampled RTL simulation</li>
      </ul>
    </li>
  </ul>
</section>
-->

<!--
<section>
  <h2>Bootstrapping Fuzzing</h2>
  <ul>
    <li class="fragment">Most HW fuzzers start from reset and run a binary on the SoC to hit some objective</li>
    <li class="fragment">Interesting objectives are harder to hit from reset vs from the middle of a workload
    <ul><li>e.g. post-OS boot, in the middle of an application</li></ul>
    </li>
    <li class="fragment">Arch and μArch checkpoints from TidalSim guarantee reachability and provides starting points for HW fuzzers</li>
  </ul>
</section>
--></section>

<section>
  <section class="center">
    <h2>6. How (pt 2): TidalSim v2</h2>

    <p class="center fragment">The proposal is structured as 3 novel extensions to TidalSim v1 that address its limitations in fundamental ways.</p>

    <ol style="list-style-type:lower-alpha;">
      <li class="fragment">Unvalidated functional warmup models
        <ul class="small">
          <li><strong>→</strong> leverage verification libraries and fuzzing to automatically discover mismatches between the warmup model and RTL</li>
        </ul>
      </li>
      <li class="fragment">Inaccurate modeling of time-driven events (e.g. timer interrupts)
        <ul class="small">
          <li><strong>→</strong> dynamically moving between arch and RTL simulation to estimate time</li>
        </ul>
      </li>
      <li class="fragment">Only works with processor cores and not heterogeneous IP
        <ul class="small">
          <li><strong>→</strong> extend sampled simulation to accelerators</li>
        </ul>
      </li>
      <!--<li class="fragment">(Optional) Hardcoded sampling methodology prevents exploration of the accuracy/throughput tradeoff space
        <ul class="small">
          <li><strong>→</strong> generalizing the spectrum of streaming sampled RTL simulation</li>
          <li><strong>→</strong> generalizing representative sampling for PC/binary-agnostic interval embeddings to enable running multi-process workloads in an OS</li>
        </ul>
      </li>-->
    </ol>

    <!-- The limitations that still exist:
    - can't work with an OS (due to virtual PCs from instruction trace conflicting with multiple processes and having incorrect basic block embeddings)
    - can't model timing accurately including timer interrupts and mtime/mcycle values
    - no functional warmup for advanced and virtual memory components (prefetcher, iTLB, dTLB, LLC)
    -->

    <!-- <ol>
      <li>Inaccurate at modeling asynchronous / timing-aware events (timer/external interrupts)</li>
      <li>Hardcoded for a single RTL design point</li>
      <li>Functional warmup models aren't validated against RTL</li>
      <li>Not warming up all necessary uarch state + resolving ambiguity in restoring arch state</li>
      <li>Interval embeddings are binary-aware (not portable) and not microarchitecture-aware (higher liklihood for errors)</li>
      <li>Modeling of I/O (off-chip communication, polling, interrupts) will be inaccurate due to uniform treatment of any memory access</li>
      <li>Interaction with core-coupled accelerators isn't properly embedded or checkpointable</li>
    </ol>-->
  </section>
</section>

<section>
  <section class="center">
    <h2>6.a: Validating Functional Warmup Models</h2>
  </section>

  <section>
    <h2>Validation Flow</h2>
    <p class="center fragment">Functional warmup models need to be validated against the behavior of their modeled RTL</p>

    <div class="center fragment">
      <img src="/assets/validation_flow-BkEDVqld.svg" />
      <figcaption class="small">The flow for validating RTL against its functional warmup model (specifically an L1 cache) using SimCommand, parametric generators, and fuzzing.</figcaption>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="/assets/validation_flow-BkEDVqld.svg" />
    </div>
  </section>

  <section>
    <h2>SimCommand: A Fast RTL Simulation API</h2>
    <ul>
      <li class="fragment">Testbench API embedded in Scala<sup>[1]</sup></li>
      <li class="fragment">Uses chiseltest as the simulator interface</li>
      <li class="fragment">Functional: testbench description and interpretation are split</li>
    </ul>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
def enqueue(data: T): Command[Unit] = for {
    _ &lt;- poke(io.bits, data)
    _ &lt;- poke(io.valid, true.B)
    _ &lt;- waitUntil(io.ready, true.B)
    _ &lt;- step(1)
    _ &lt;- poke(io.valid, false.B)
} yield ()
    </pre></code>

    <ul class="smallish">
      <li class="fragment">20x faster than cocotb and chiseltest, parity with SystemVerilog + VCS</li>
      <li class="fragment">Enables writing performant testbenches with fork/join constructs in Scala</li>
    </ul>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Iyer, Vighnesh, et. al., SimCommand: A High Performance Multi-Threaded RTL Testbench API, OSCAR Workshop 2022
      </p>
    </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="/assets/validation_flow-BkEDVqld.svg" />
    </div>
  </section>

  <section>
    <h2>Parametric Random Stimulus Generators</h2>

    <ul class="small">
      <li class="fragment">We designed a Scala eDSL for parametric random stimulus generation<sup>[1]</sup></li>
      <li class="fragment">Supports constrained and imperative randomization of Scala and Chisel datatypes</li>
    </ul>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
val intGen: Gen[Int] = Gen[Int].range(0, 100)
</pre></code>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
val seqGen: Gen[Seq[Int]] = for {
  lit &lt;- Gen.range(1, 100)
  tailGen &lt;- Gen.oneOf(Gen(Seq()) -&gt; 0.1, seqGen -&gt; 0.9),
  seqn &lt;- tailGen.map(t =&gt; lit +: t)
} yield seqn
</pre></code>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
object MemOp extends ChiselEnum
case class MemTx extends Bundle {
  val addr = UInt(32.W)
  val data = UInt(64.W)
  val op = MemOp
}
val memTxGen: Gen[MemTx] = Gen[MemTx].uniform
</pre></code>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Iyer, Vighnesh, et. al., New Embedded DSLs for HW Design and Verification, PLARCH Workshop 2023
      </p>
    </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="/assets/validation_flow-BkEDVqld.svg" />
    </div>
  </section>

  <section>
    <h2>RTL Coverage for Simulation Feedback</h2>

    <div class="container" style="grid-template-columns:1fr 1fr">
      <div>
        <img width="100%" src="/assets/1_coverage_figure_m_n-DrfczUeS.svg" />
      </div>
      <div>
        <ul class="smallish">
          <li class="fragment">Coverage implemented as a hardware IR compiler pass rather than baked into the RTL simulator</li>
          <li class="fragment">Easy to add new coverage metrics via static analysis of the RTL netlist</li>
          <li class="fragment">Leverage simulator independent coverage methodology for coverage instrumentation of long-lived uArch RTL</li>
        </ul>
      </div>
    </div>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Laeufer, Kevin; Iyer, Vighnesh, et. al., Simulator Independent Coverage for RTL Hardware Languages, ASPLOS 2023
      </p>
    </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="/assets/validation_flow-BkEDVqld.svg" />
    </div>
  </section>

  <section>
    <h2>Parametric Fuzzing</h2>

    <ul class="smallish">
      <li class="fragment">Leverage fast RTL simulation APIs, parametric stimulus generators, and coverage instrumentation for <em>parametric fuzzing</em><sup>[1]</sup></li>
    </ul>

    <img class="fragment" src="/assets/parametric_fuzzing_loop-DuUbs-kn.svg" />

    <ul class="smallish">
      <li class="fragment">Parametric fuzzing mutates the bytestream <em>going into</em> a parametric generator rather than the DUT directly<sup>[2]</sup></li>
      <li class="fragment">We augment typical parametric fuzzing with <em>mark-driven mutation</em></li>
    </ul>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Iyer, Vighnesh, et. al., New Embedded DSLs for HW Design and Verification, PLARCH Workshop 2023<br />
      [2]: Padhye, R., Lemieux, C., Sen, K., Papadakis, M. and Le Traon, Y., 2019. Semantic fuzzing with zest. ACM SIGSOFT.
      </p>
    </div>
    </div>
  </section>

  <section>
    <h2>Parametric Fuzzing - Demo Using Spike</h2>

    <div class="center">
      <img width="80%" class="fragment" src="/assets/spike_fuzzing-iAbT2FCS.svg" />
    </div>

    <div class="container" style="grid-template-columns: 1.4fr 1fr;">
      <div>
        <ul class="smallish">
          <li class="fragment">Use spike's L1 dcache model's miss rate as feedback to produce RISC-V programs that maximize it</li>
          <li class="fragment">Using parametric fuzzing, we can automatically construct RISC-V programs to maximize any uArch metric given a small set of RISC-V sequence primitives</li>
        </ul>
      </div>
      <div>
        <img width="100%" class="fragment" src="/assets/spike_fuzzing_result--49tMnff.png" />
      </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="/assets/validation_flow-BkEDVqld.svg" />
    </div>
  </section>
</section>

<section>
  <section class="center">
    <h2>6.b: Putting the 'Tidal' in TidalSim</h2>
  </section>

  <section>
    <h2 style="font-size:1.9rem;">Issues with Time Modeling in Sampled Simulation</h2>

    <ul class="smallish">
      <li class="fragment">Prior work runs uArch simulators in "syscall emulation" mode when evaluating workloads (e.g. SPEC), not modeling any OS-application interactions</li>
      <li class="fragment">Real workloads contain many interactions between processes and the OS which are sensitive to the modeling of time</li>
    </ul>

    <div class="center fragment">
      <img width="60%" src="/assets/timer_interrupts-BAxG238I.svg" />
    </div>

    <p class="center fragment">Consider timer interrupts: naive functional simulators will just advance one timestep per commited instruction, not matching RTL!</p>
  </section>

  <section>
    <h2>TidalSim to Model Time Accurately</h2>

    <div class="center fragment">
      <img width="80%" src="/assets/timer_interrupts-BAxG238I.svg" />
    </div>

    <ul class="smallish">
      <li class="fragment">We propose bouncing between functional and RTL simulation, where performance metrics from RTL sim impacts time advancement in functional sim</p>
      <li class="fragment">To avoid simulating every interval in RTL sim, we leverage interval embeddings to estimate IPC on the fly</li>
    </ul>
    <!-- Insert image of bouncing between simulators and using interval embeddings to estimate actual time advancement-->
  </section>
</section>

<section>
  <section class="center">
    <h2>6.c: Sampled Simulation with Accelerators</h2>
  </section>

  <section>
    <h2>What Makes Accelerators Suitable for Sampled Simulation?</h2>

    <ul>
      <li class="fragment">Accelerator architectural state is large and explicit
        <ul>
          <li class="fragment"><strong>→</strong> snapshotting is easy</li>
          <li class="fragment"><strong>→</strong> functional warmup is unnecessary</li>
        </ul>
      </li>
      <li class="fragment">Accelerator usage is often repeated in workloads
        <ul>
          <li class="fragment"><strong>→</strong> clustering accelerator usage embeddings is reasonable</li>
          <li class="fragment"><strong>→</strong> potential for massive simulation throughput improvement</li>
        </ul>
      </li>
      <li class="fragment">Accelerator behavior is consistent
        <ul>
          <li class="fragment"><strong>→</strong> accelerator performance is consistent from one dataset to another</li>
          <li class="fragment"><strong>→</strong> embeddings don't need to be aware of the accelerator microarchitecture / latent state</li>
        </ul>
      </li>
    </ul>
    <!-- Talk about how accelerator arch state is explicit and accelerators often don't have long-lived uarch state (that requires functional warmup) -->
    <!-- Extend arch snapshotting to accelerator state too + add restoration capabilities for accelerator state -->
  </section>

  <section>
    <h2>Extending Interval Embeddings to Accelerators</h2>

    <div class="center">
      <img src="/assets/accelerators-CFl06pWn.svg" />
    </div>

    <ul class="smallish">
      <li class="fragment">Incorporate accelerator state and the semantics of the accelerator ISA to the embedding</li>
      <li class="fragment">Can capture and embed accelerator interactions with system memory and with internal compute units</li>
      <li class="fragment">In the case of Gemmini, we must also consider instruction dependencies and out-of-order execution + memory contention from multiple accelerators</li>
    </ul>
    <!-- Need to incorporate accelerator state and the semantics of accelerator ISA instructions to the embedding.
    Consider case of Gemmini - intervals are similar if they execute similar gemmini instructions under same gemmini configuration. can use number of bytes mvin-ed / mvout-ed from sp/acc as a feature.
    Feature tuning needs to be precise here.-->
  </section>
</section>

<section>
  <section class="center">
    <h2>Backup: 6.d: Generalizing the Spectrum of Sampled Simulation</h2>
    <!-- generalization + streaming (no preprocessing step required)
      <li>Not general or streaming
        <ul>
          <li>Hardcoded Simpoint-style sampled simulation</li>
          <li>Requires multiple passes over the commit trace / multiple runs of spike</li>
        </ul>
      </li>
    -->
  </section>

    <!-- - We have implemented one specific simulator design point, but now we will generalize it
    - We will devise a parameterized simulator that can implement SMARTs, Simpoint, and hybrid-embedding/sampling approaches to simulation
    - Our formalization will
        - Produce output metrics such as cost, runtime, throughput, latency, time granularity, error bounds
        - In terms of variables such as number of dynamic instructions, number of cores, RTL sim throughput, and of course the simulation methodology
      -->

  <section>
    <h2>Sampled Simulation Techniques</h2>

    <div class="center fragment">
      <img width="70%" src="/assets/simulation_techniques-BCLw6cXl.svg" />
    </div>

    <p class="center fragment">Simulation techniques encompass SMARTS, SimPoint, hybrid variants, eager parallel RTL simulation, and many more</p>
  </section>

  <section>
    <h2>A Formalization and Simulation Model</h2>

    <div class="center fragment">
      <img width="40%" src="/assets/simulation_techniques-BCLw6cXl.svg" />
    </div>

    <ol class="small">
      <li class="fragment">Only considering techniques that can operate in a streaming fashion, develop a parameterized version of TidalSim
        <ul>
          <li>Streaming necessitates new incremental unsupervised learning algorithms</li>
        </ul>
      </li>
      <li class="fragment">Formalize the interfaces between arch sim, uArch models, and RTL sim</li>
      <li class="fragment">Formalize and parameterize simulation methodology to encompass all prior techniques
        <ul>
          <li>Consider <strong>input parameters</strong> such as interval length ($N$), number of host cores ($n_{cores}$), RTL simulation throughput ($T_{rtl}$), sampling technique ($i \rightarrow \{0, 1\}$)</li>
          <li>Produce estimated <strong>output metrics</strong> such as cost, runtime, aggregate throughput, latency, time-granularity of output, error bounds</li>
        </ul>
      </li>
    </ol>
  </section>

  <section>
    <h2>PC/Binary-Agnostic Embeddings</h2>
    <!-- <li><strong>→</strong> generalizing representative sampling for PC/binary-agnostic interval embeddings to enable running multi-process workloads in an OS</li>-->

    <ul>
      <li class="fragment">Basic block embedding assumes
        <ul>
          <li>There is a static PC <strong>→</strong> basic block mapping</li>
          <li>Intervals with similar basic block traversals have similar uArch behavior</li>
        </ul>
      </li>
      <li class="fragment">Our embeddings should be PC/binary-agnostic to support portability and multi-process workloads in an OS
        <ul>
          <li>Most prior work only runs single-process workloads using syscall proxies</li>
          <li>Real workloads are heavily affected by interactions between the OS and userspace processes</li>
        </ul>
      </li>
      <li class="fragment">We will explore embeddings with features such as
        <ul>
          <li>Instruction mix, function call frequency, instruction dependencies</li>
          <li>Microarchitectural behaviors: I/D cache misses, BP model mispredicts, TLB behavior</li>
        </ul>
      </li>
    </ul>
  </section>
</section>


<!-- <section>
  <h2>2. Modeling Timing-Aware Events (Dynamic Simulation)</h2>
  going from one-direction simulation to dynamically changing simulators up and down the stack during execution
</section>

<section>
  <h2>3. Leveraging Chisel for State Injection</h2>
</section>

<section>
  <h2>4. Validating Functional Warmup Models</h2>
</section>

<section>
  <h2>5. Long-Lived uArch State Identification</h2>
</section>

<section>
  <h2>5. Resolving Ambiguity in Forcing Arch State</h2>
</section>

<section>
  <h2>6. Better Interval Embeddings</h2>
</section>

<section>
  <h2>7. Modeling I/O</h2>
</section>

<section>
  <h2>8. Sampled Simulation with Accelerators</h2>
</section>
-->
<section>
  <section class="center">
    <h2>7. Thesis Outline</h2>
  <!--This semester: v0.1 to v1
  Summer: v1 to v2 (improvements in next section)
  Next semester: Leverage v2 for case studies
  Spring 2025: Finish thesis writing + graduate-->
  </section>

  <section>
    <h2>Outline</h2>
    <ol style="font-size: 1rem;">
      <li class="fragment">Motivation and background</li>
      <li class="fragment">Implementation and evaluation of TidalSim v0.1 - <strong>Completed</strong>
        <ul>
          <li>Mixed functional/RTL simulation, IPC/MPKI/cache behavior estimation</li>
          <li>Clean estimation on all baremetal workloads (MiBench, Embench)</li>
        </ul>
      </li>
      <li class="fragment">Implementation and evaluation of TidalSim v1 - <strong>March 2024</strong>
        <ul>
          <li>Functional warmup of all long-lived units</li>
          <li>Demonstrate &lt;1% IPC error</li>
        </ul>
      </li>
      <!--<li class="fragment">Generalizing the spectrum of streaming sampled simulation
        <ul>
          <li>Formalization of sampled simulation</li>
          <li>Investigating binary-agnostic embeddings</li>
          <li>Running full-stack applications on top of an OS</li>
        </ul>
      </li>-->
      <li class="fragment">Validating functional warmup models - <strong>May 2024</strong>
        <ul>
          <li>SimCommand, parametric stimulus generation APIs, parametric fuzzing</li>
          <li>Heuristics for comparing functional models and RTL uArch structures</li>
        </ul>
      </li>
      <li class="fragment">Modeling time accurately - <strong>June 2024</strong>
        <ul>
          <li>Dynamically switching between RTL and functional simulation for modeling time accurately</li>
          <li>Time estimation fidelity, comparison to FireSim in modeling timer interrupts</li>
        </ul>
      </li>
      <li class="fragment">Sampled simulation for accelerators - <strong>August 2024</strong>
        <ul>
          <li>New embeddings for code that uses accelerators</li>
        </ul>
      </li>
      <li class="fragment">Using TidalSim for hardware DSE - <strong>September 2024</strong>
        <ul>
          <li>Language-level support for arch/uArch state marking and testharness synthesis</li>
          <li>Prefetcher optimization case study to show superior DSE latency and accuracy vs other approaches</li>
        </ul>
      </li>
      <li class="fragment">Using TidalSim for coverpoint synthesis - <strong>November 2024</strong></li>
    </ol>
  </section>
</section>


<section data-visibility="hidden">
  <h2>Problem Overview</h2>

  <p class="center fragment">Fast RTL-level μArch simulation and performance metric / interesting trace extraction</p>
  <p class="center fragment"><em><strong>enables</strong></em></p>
  <p class="center fragment">Rapid RTL iteration with performance, power modeling, and verification evaluation on real workloads</p>
  <hr class="fragment">
  <p class="center fragment">How can we achieve high throughput, high fidelity, low latency μArch simulation with RTL-level interesting trace extraction?</p>
</section>

<section data-visibility="hidden">
  <h2>Motivation</h2>

  <ul>
    <li class="fragment">We want fast design iteration and evaluation of PPA + verification given real workloads
    <!--Fast design iteration and evaluation of PPA + verification requires stimulus that's representative and comprehensive wrt real workloads (execution fragments)-->
    </li>
    <li class="fragment">The enablers are: <em>fast and accurate μArch simulation</em> and a way to identify <em>unique execution fragments</em>
      <ul>
        <li class="fragment"><em>Performance estimation:</em> Performance metric extraction from fast RTL simulation</li>
        <li class="fragment"><em>Power macromodeling:</em> Extraction of interesting program traces for clustering/training</li>
        <li class="fragment"><em>Verification:</em> Extraction of traces for coverpoint/specification synthesis + state seeding for fuzzing</li>
      </ul>
    </li>
  </ul>
</section>

<section data-visibility="hidden">
  <h2>Pre-Silicon Microarchitecture Simulation</h2>

  <ul>
    <li class="fragment"><em>Performance estimation:</em> Impact of μArch optimizations / HW parameters on real workloads</li>
    <li class="fragment"><em>Power macromodeling:</em> Identification of important netlist nodes in power model + traces for training</li>
    <li class="fragment"><em>Verification:</em> Bootstrapping fuzzing loops + coverpoint synthesis</li>
  </ul>
</section>

<section data-visibility="hidden">
  <section>
    <h2>Performance Optimizations</h2>
    <ul>
      <li class="fragment">Currently two runs of the binary through spike are needed
      <ul>
        <li>One to get a commit log for basic block extraction, embedding, and clustering</li>
        <li>One more to dump arch checkpoints for chosen samples</li>
      </ul>
      </li>
      <li class="fragment">We can take regular checkpoints during the first execution to make arch checkpoint collection fast</li>
    </ul>
  </section>

  <section>
    <h2>Validation of State Injection</h2>
    <ul>
      <li class="fragment">There is no arch state comparison at the end of a checkpoint run in RTL simulation</li>
      <li class="fragment">We will standardize a arch state schema and dump a reference state from spike to check against</li>
    </ul>
  </section>

  <section>
    <h2>Handling Large Interval Lengths</h2>
    <ul>
      <li class="fragment">Real programs will use large intervals (1-10M instructions)</li>
      <li class="fragment">Selected intervals can't be run in their entirety in RTL simulation</li>
      <li class="fragment">Sub-sampling intervals with random sampling is required</li>
    </ul>
  </section>
</section>

<section data-visibility="hidden">
  <h2>Conclusion</h2>

  <div class="container" style="grid-template-columns: 1fr 1.4fr;">
  <div>
  <ul>
    <li class="fragment">We want rapid iteration wrt PPA evaluation and verification objectives</li>
    <li class="fragment">We need fast RTL-level simulation with trace extraction</li>
    <li class="fragment">We propose <strong>TidalSim</strong>, a multi-level simulation methodology to enable rapid HW iteration</li>
  </ul>
  </div>
  <div style="display:grid; align-content: center;">
    <img src="/assets/overview-_bAKuIOR.svg" />
  </div>
  </div>

  <p class="center fragment"><a href="https://github.com/euphoric-hardware/tidalsim">TidalSim (github.com/euphoric-hardware/tidalsim)</a></p>
</section>

        </div>
    </div>

  </body>
</html>