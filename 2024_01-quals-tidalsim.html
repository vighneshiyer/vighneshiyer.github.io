<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Vighnesh Iyer's Qualifying Exam - TidalSim: Multi-Level Microarchitectural Simulation and Applications in Verification</title>
    <meta name="description" content="A Unified Microarchitectural Simulation Framework to Identify and Leverage Unique Aspects of Workloads on Heterogeneous SoCs for Power and Performance Estimation and Verification">
    <meta name="author" content="Vighnesh Iyer">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <style>
.reveal h2 {
  margin-top: 1rem !important;
}
</style>
    <script type="module" crossorigin src="/assets/2024_01-quals-tidalsim-ddea4b1b.js"></script>
    <link rel="modulepreload" crossorigin href="/assets/reveal.esm-cde48b62.js">
    <link rel="stylesheet" href="/assets/reveal-9088ee32.css">
    <link rel="stylesheet" href="/assets/remark-ish-d5a15852.css">
  </head>

  <body vocab="http://schema.org/" typeof="PresentationDigitalDocument">
    <span property="publisher" style="display: none;">UC Berkeley (Jan 2024)</span>
    <time pubdate property="datePublished" datetime="2023-12-29" style="display: none;">December 29, 2023</time>
    <div class="reveal">
        <div class="slides">
            <section class="center">
  <h1>TidalSim: A Unified Microarchitectural Simulation Framework</h1>
  <h2 style="font-weight: 400;">To Identify and Leverage <strong>Unique Aspects of Workloads</strong> on <strong>Heterogeneous SoCs</strong> for Power and Performance Estimation and Verification</h2>
  <h3 style="font-weight: 500;">Vighnesh Iyer</h3>
  <h3 style="font-weight: normal;">Qualifying Exam Presentation</h3>
  <h4 style="font-weight: normal;">Wednesday, January 17th, 2024</h4>
</section>

<section>
  <h2>Talk Outline</h2>
  <ol>
    <li class="fragment"><strong>Why</strong>: What is the problem I'm solving?</li>
    <li class="fragment"><strong>What</strong>: What is the thing I want to build?</li>
    <li class="fragment"><strong>Prior work</strong> + <strong>what's new</strong> about my proposal?</li>
    <li class="fragment"><strong>How (pt 1)</strong>: A prototype implementation of my proposal</li>
    <li class="fragment"><strong>How (pt 2)</strong>: Addressing faults of and generalizing the prototype
      <ul style="font-size: 1.4rem;">
        <li>Each point roughly corresponds to a thesis chapter</li>
      </ul>
    </li>
    <li class="fragment"><strong>Case studies</strong> / <strong>applications</strong>: How will we use what we built to do something that was impossible before?</li>
    <li class="fragment"><strong>Thesis outline</strong> and paper plan</li>
  </ol>
</section>

<section>
<section class="center">
  <h2 class="center">1. Why: What Is the Problem?</h2>
  <ul>
    <li class="fragment">Emergence of domain-specialized heterogeneous SoCs</li>
    <li class="fragment">Rapid design iteration is the key to achiving optimal PPA + time to market</li>
    <li class="fragment">Existing pre-silicon evaluation (power, performance, functionality) techniques on real workloads are unsuitable for rapid iteration</li>
  </ul>
</section>

<section>
  <h2>The End of "Free" Technology Scaling</h2>

  <p class="center fragment"><strong>Moore's Law</strong>: transistor counts double while cost/transistor halves every 2 years</p>

  <div class="container fragment">
    <div>
      <img width="60%" src="/assets/wafer_cost_trend-d5ea3cec.jpg" />
    </div>
    <div>
      <img width="60%" src="/assets/per_transistor_cost_trend-0630dc57.png" />
    </div>
  </div>

  <ul class="small">
    <li class="fragment">Per-wafer and per-transistor costs continue to grow with process scaling<sup>[1, 2]</sup> unless heavily amortized</li>
  </ul>

  <p class="fragment center"><strong>→</strong> Transistors are no longer free</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: <a href="https://www.semianalysis.com/p/the-dark-side-of-the-semiconductor">SemiAnalysis: The Dark Side of the Semiconductor Design Renaissance</a>.<br/>
    [2]: <!-- https://www.fabricatedknowledge.com/p/the-rising-tide-of-semiconductor -->
<a href="https://filecache.investorroom.com/mr5ir_marvell/131/download/Marvell%20Investor%20Day%202020.pdf">Marvell Investor Day 2020</a>.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Stagnation of Single Thread Performance</h2>

  <p class="center fragment"><strong>Dennard Scaling</strong>: power density is constant with technology scaling</p>

  <div class="container fragment">
    <div>
      <img width="80%" src="/assets/single_thread_performance_trend-77c94e5f.png" />
    </div>
    <div>
      <img width="100%" src="/assets/50_years_of_microprocessor_trend_data-dad03855.png" />
    </div>
  </div>

  <ul class="small">
    <li class="fragment">General-purpose single-thread performance has stagnated<sup>[1,2]</sup></li>
  </ul>

  <p class="fragment center"><strong>→</strong> Can't rely on technology scaling for gains in performance</p>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: <a href="https://www.doc.ic.ac.uk/~wl/teachlocal/arch/papers/cacm19golden-age.pdf">CACM: A New Golden Age for Computer Architecture</a>.<br/>
    [2]: <a href="https://github.com/karlrupp/microprocessor-trend-data">Karl Rupp; 50 Years of Microprocessor Trend Data</a>.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>The Consequences of These Trends</h2>

  <div class="container" style="text-align: center; grid-template-columns: 1fr 1fr;">
    <div class="fragment">
      <p style="margin-top: 0;"><strong>End of Moore's Law</strong></p>
      <p style="margin-top: 0;"><strong>→</strong> $/transistor not falling</p>
      <p style="margin-top: 0;"><strong>→</strong> Transistors are no longer free</p>
      <p style="margin-top: 0; margin-bottom: 0;"><strong>→</strong> <strong>Need aggressive PPA optimization</strong></p>
    </div>
    <div class="fragment">
      <p style="margin-top: 0;"><strong>End of Dennard Scaling</strong></p>
      <p style="margin-top: 0;"><strong>→</strong> Power density <em>increasing</em></p>
      <p style="margin-top: 0;"><strong>→</strong> <em>GPP</em> performance stagnating</p>
      <p style="margin-top: 0; margin-bottom: 0;"><strong>→</strong> <strong>Need domain-specialization to not stagnate</strong></p>
    </div>
  </div>

  <hr class="fragment">

  <p class="center fragment" style="margin-top: 0.5rem; margin-bottom: 0.5rem;">Motivates two trends in SoC design</p>

  <ol>
    <li class="fragment">Heterogeneous cores
      <ul>
        <li>Cores targeting different power/performance curves</li>
        <li>Domain-specific cores</li>
        <li>Core-coupled accelerators (ISA extensions)</li>
      </ul>
    </li>
    <li class="fragment">Domain-specific accelerators</li>
  </ol>
  <!--<em>General-purpose</em> single thread performance is stagnating, but tuned cores still can squeeze a lot more out-->
</section>

<section>
  <h2>The New-Era of Domain-Specialized Heterogeneous SoCs</h2>
  <!-- Raptor Lake, Apple M3, Snapdragon 8 Gen 3, Exynos 2200 -->
  <!-- Server class, laptop class, smartphone class - similar heterogeneous convergence -->

  <div class="r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="100%" src="/assets/raptor_lake-cd021bc9.jpg">
      <figcaption class="small center"><a href="https://twitter.com/Locuza_/status/1574892888491790336">Locuza (Twitter): Raptor Lake-S Die Analysis</a></figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/exynos_2200-2271bf90.jpg">
      <figcaption class="small center"><a href="https://locuza.substack.com/p/die-analysis-samsung-exynos-2200">Locuza Substack: Die analysis: Samsung Exynos 2200 with RDNA2 graphics</a></figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/a17_pro-d4816c44.jpg">
      <figcaption class="small center"><a href="https://twitter.com/Frederic_Orange/status/1711432628908253520/photo/1">@Frederic_Orange Twitter: A17 Pro Die Analysis</a></figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="40%" src="/assets/m3_max-07851645.jpg">
      <figcaption class="small center"><a href="https://twitter.com/highyieldYT/status/1719306863341113349/photo/1">@highyieldYT Twitter: M3 Max Die Analysis</a></figcaption>
    </div>
  </div>
</section>

<section>
  <h2>Specialized Core Microarchitectures</h2>

  <!-- Another point: Different CPUs have very different pipelines and designs based on power/perf tradeoff + workload tuning -->
  <!-- It is not just hardware parameter sweeping!!! -->
  <div class="container">
    <div>
      <img src="/assets/cortex_a77_block_diagram-160529d3.svg" />
      <figcaption class="small center"><a href="https://en.wikichip.org/wiki/arm_holdings/microarchitectures/cortex-a77">WikiChip: Cortex-A77 Microarchitecture Block Diagram</a></figcaption>
    </div>
    <div>
      <ul>
        <li class="fragment">Different CPUs in the same SoC aren't just variants of the same underlying microarchitecture
          <!--<ul>
            <li class="fragment">They have completely independent designs!</li>
            <li class="fragment">Hardware parameter space exploration is performed for a given microarchitectural blueprint</li>
            <li>
          </ul>-->
        </li>
        <li class="fragment">The broad categories of microarchitectural iteration
          <ol style="font-size: 1.2rem;">
            <li class="fragment">Creating a new structure (vector unit, prefetcher, new type of branch predictor)</li>
            <li class="fragment">Optimizing an existing structure (ROB dispatch latency, new forwarding path)</li>
            <li class="fragment">Tuning hardware parameters (cache hierarchy and sizing, LSU queue sizing)</li>
          </ol>
        </li>
        <li class="fragment">Must evaluate PPA <em>tradeoffs</em> of each modification on specific workloads</li>
        <!-- It's about tradeoffs on PPA on specific workloads! Not about optimizing some big function of HW parameters to PPA. -->
      </ul>
    </div>
  </div>
</section>

<section>
  <h2>Microarchitecture Design Challenges</h2>

  <div class="fragment" style="display: grid; place-items: center;">
    <img width="50%" src="/assets/ibs_cost_per_node_trend-e774145a.webp" />
    <figcaption class="small center"><a href="https://semiengineering.com/big-trouble-at-3nm/">IBS: IC design costs growing for each node</a></figcaption>
  </div>

  <!-- Time limit! Need to spin as fast as possible during design phase and then freeze. Number of spins dictates how much performance can be squeezed out per generation! -->
  <!-- What is the challenge? pick specializations that are possible and evaluate them -->
  <!-- Optimizing real-world software pre-silicon is very hard -->

  <ul class="smallish" style="margin-top: 1rem;" >
    <li class="fragment">We want optimal designs for heterogeneous, domain-specialized, workload-tuned SoCs</li>
    <li class="fragment">Limited time to iterate on microarchitecture and <em>optimize PPA</em> on <em>real workloads</em></li>
    <li class="fragment">Time per evaluation (microarchitectural iteration loop) limits number of evaluations
    </li>
  </ul>
  <p class="center fragment">More evaluations = more opportunities for optimization</p>
</section>

<section>
  <h2>The Microarchitectural Iteration Loop</h2>

  <div class="center">
    <img src="/assets/uarch_iteration_flow_v2-cb986edd.svg" />
  </div>

  <p class="center fragment">We want an "Evaluator" that has low latency, high throughput, high accuracy, low cost, and rich output collateral</p>
  <p class="center fragment"><strong>Existing tools cannot deliver on all axes</strong></p>
  <!-- Can't get all axes using any existing tool (low latency, high throughput, low cost, high accuracy, rich output collateral)! -->
  <!-- <p class="center fragment">Existing pre-silicon evaluation (power, performance, functionality) techniques on real workloads are unsuitable for rapid iteration</p> -->
</section>

<section>
  <h2>Limitations of Existing Evaluators</h2>

  <div class="center">
    <img width="60%" src="/assets/uarch_iteration_flow_v2-cb986edd.svg" />
  </div>

  <ul class="smallish fragment">
    <li><strong>ISA simulation</strong>: no accuracy</li>
    <li><strong>Trace/Cycle uArch simulation</strong>: low accuracy, insufficient output collateral</li>
    <li><strong>RTL simulation</strong>: low throughput</li>
    <li><strong>FPGA prototyping</strong>: high latency</li>
    <li><strong>HW emulators</strong>: high cost</li>
  </ul>

  <p class="center fragment"><strong>We will propose a simulator that can deliver on all axes.</strong></p>
</section></section>

<section>
<section class="center">
  <h2 class="center">2. What: Our Vision for TidalSim</h2>
  <p class="center fragment"><strong>What if</strong> we had a simulator that:</p>

  <ol>
    <li class="fragment">Is <strong>fast</strong> enough to run real workloads on heterogeneous SoCs</li>
    <li class="fragment">Is <strong>accurate</strong> enough to use confidently for microarchitectural DSE</li>
    <li class="fragment">Has <strong>low latency</strong> to not bottleneck the hardware iteration loop</li>
    <li class="fragment">Can produce <strong>RTL-level collateral</strong> for applications from power modeling to application-level profiling to verification
      <ul style="font-size: 1.4rem;"><li class="fragment">Can automatically <strong>isolate and extract benchmarks</strong> from long workloads by identifying unique aspects with respect to power, performance, and functionality</li></ul>
    </li>
  </ol>
</section>

<section>
  <h2>What: TidalSim</h2>
  <!-- How does this tool address the challenges we posed in the Why section? -->

  <div class="center">
    <img src="/assets/uarch_iteration_flow_tidalsim-ba904d05.svg" />
    <figcaption class="small center"><strong>TidalSim</strong>: a fast, accurate, low latency, low cost microarchitectural simulator that produces RTL-level collateral for performance and power estimation and verification on real workloads.</figcaption>
  </div>
</section>

<section>
  <h2>Scope of Thesis</h2>

  <div class="center">
    <img width="50%" src="/assets/uarch_iteration_flow_tidalsim-ba904d05.svg" />
  </div>

  <ol>
    <li class="fragment">Implementation of TidalSim</li>
    <li class="fragment">Evaluation of TidalSim for performance and power estimation on large workloads
    <ul style="font-size: 1.4rem;"><li>Embench, GAP, SPEC, HyperProtoBench, MLPerf, CloudSuite</li></ul>
    </li>
    <li class="fragment">Case studies for hardware DSE, power macromodel training, and coverpoint synthesis</li>
  </ol>
</section></section>

<section>
<section class="center">
  <h2 class="center">3. Background and Prior Work</h2>
  <ul>
    <li class="fragment">An overview of simulation broadly
      <ul><li>Abstractions used in hardware modeling</li></ul>
    </li>
    <li class="fragment">Existing microarchitectural simulators</li>
    <li class="fragment">Sampled simulation techniques
      <ul>
        <li>Phase behavior of programs</li>
        <li>SimPoint: Interval embedding and clustering</li>
        <li>SMARTs: Reservoir sampling and bounding sampling errors</li>
        <li>Functional warmup techniques</li>
        <li>Detailed warmup</li>
      </ul>
    </li>
    <li class="fragment">Prior work on rapid microarchitectural evaluation</li>
  </ul>
</section>

<section>
  <h2>A Broad View of Simulation</h2>

  <div class="center">
    <img src="/assets/simulators_broadly-ce0e20cf.svg" />
    <figcaption class="small center">A high-level, generic view of the input and outputs of a simulator.</figcaption>
  </div>

  <ul style="margin-top: 1rem;">
    <li class="fragment">Simulation is the workhorse of architecture evaluation</li>
    <li class="fragment">Simulation inputs can have wide variation of fidelity
      <ul>
        <li><strong>Hardware spec</strong>: high-level models to detailed microarchitecture</li>
        <li><strong>Workload</strong>: high-level algorithmic description to concrete binary</li>
      </ul>
    </li>
    <li class="fragment">The fidelity of simulation outputs tracks that of the inputs</li>
    <!--<li>Inputs: architecture specification or framework, workload
      <ul>
        <li>Specification can be high-level (blocks + instruction spec + latencies) or very detailed</li>
        <li>Workload can be high-level (memory access pattern) or fully concrete</li>
      </ul>
    </li>
    <li>Outputs: execution trace/metrics - how does the architecture execute the workload? - notion of time granularity and space granularity + PPA stuff if available </li>-->
  </ul>

</section>

<section>
  <h2>Hardware Abstractions</h2>

  <p class="center fragment">There are roughly <strong>4 levels of hardware abstractions</strong> used in architecture evaluation</p>

  <ol>
    <li class="fragment">Architectural (functional) models</li>
    <li class="fragment">Microarchitectural models (<em>"rough"</em>) with approximate state and timing</li>
    <li class="fragment">Microarchitectural models (<em>"detailed"</em>) with more refined state and timing</li>
    <li class="fragment">Register-transfer level (RTL) models with full fidelity state and timing</li>
  </ol>
</section>

<section>
  <h2>Hardware Abstractions: Architectural (Functional) Models</h2>

  <p class="fragment center">Functional simulators emulate an architecture and can execute workloads (e.g. ELF binaries).</p>
  <p class="fragment center">They only model <em>architectural</em> state, defined in an ISA specification. No <em>microarchitectural</em> state is modeled.</p>

  <ul>
    <li class="fragment">Examples
      <ul>
        <li>RISC-V: <a href="https://github.com/riscv-software-src/riscv-isa-sim">spike</a>, <a href="https://github.com/chipsalliance/dromajo">dromajo</a>, <a href="https://www.imperas.com/riscvovpsim-free-imperas-risc-v-instruction-set-simulator">Imperas riscvOVPSim</a></li>
        <li>Multi-ISA (x86, ARM, RISC-V): <a href="https://www.qemu.org/">qemu</a></li>
      </ul>
    </li>
    <li class="fragment">Very fast (10-1000 MIPS), low startup latency (instant)</li>
    <li class="fragment">Cannot estimate PPA</li>
  </ul>
</section>

<section>
  <h2>Hardware Abstractions: "Rough" uArch Models - Micro-Kernel Accelerators</h2>

  <ul class="smallish">
    <li class="fragment">Microarchitecture is modeled with high-level blocks with a dataflow and timing relationship</li>
    <li class="fragment">Prior Work: Aladdin<sup>[1]</sup> is a microarchitecture estimation and simulation tool for analyzing the PPA of potential accelertors for kernels written in C</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/aladdin_architecture-224f581c.png">
      <figcaption class="small center">System architecture assumed by Aladdin</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="70%" src="/assets/aladdin_flow-2a350c5a.png">
      <figcaption class="small center">Aladdin flow. Inputs: workload. Outputs: dataflow microarchitecture + PPA</figcaption>
    </div>
    <!--<div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="20%" src="./figs/quals/aladdin_simulation.png">
      <figcaption class="small center">Aladdin simulation</figcaption>
    </div>-->
  </div>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote">
    [1]: Shao, Y.S., Reagen, B., Wei, G.Y. and Brooks, D., 2014. Aladdin: A pre-rtl, power-performance accelerator simulator enabling large design space exploration of customized architectures. ACM SIGARCH.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: "Rough" uArch Models - ML Accelerators</h2>

  <ul class="small">
    <li class="fragment">Rough uArch models are used for evaluating ML accelerator architectures, dataflows, and workload mappings</li>
    <li class="fragment">Prior Work: Timeloop<sup>[1]</sup>, Accelergy<sup>[2]</sup> provides a framework for describing accelerator microarchitecture with parameterizable blocks (PEs, scratchpads), workload mappings, and simulating workloads for PPA estimates</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/accelergy_example_arch-9ab3cfbd.png" style="margin:0;">
      <figcaption class="small center">An example microarchitecture modeled by Timeloop</figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/timeloop_arch_definition-8744bc13.png" style="margin:0;">
      <figcaption class="small center">Microarchitecture description schema provided by Timeloop</figcaption>
    </div>
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="30%" src="/assets/timeloop_workload_definition-42f6e044.png" style="margin:0;">
      <figcaption class="small center">Timeloop's schema for defining workloads and their mapping</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="70%" src="/assets/timeloop_outputs-40cebbdf.png" style="margin:0;">
      <figcaption class="small center">Timeloop + Accelergy flow. Inputs: workload. Outputs: ML microarchitecture + PPA</figcaption>
    </div>
  </div>

  <div class="fragment">
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Parashar, A., et. al., 2019. Timeloop: A systematic approach to dnn accelerator evaluation. ISPASS.<br/>
    [2]: Wu, Y.N., Emer, J.S. and Sze, V., 2019. Accelergy: An architecture-level energy estimation methodology for accelerator designs. ICCAD.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: "Rough" uArch Models - Cores</h2>
  <!-- Wattch, CACTI, McPAT (CPU modeling) -->

  <ul class="smallish">
    <li class="fragment">Rough uArch models are also common for evaluating core microarchitectures</li>
    <li class="fragment">Prior Work: McPAT<sup>[1]</sup> models CPUs with a parameterizable out-of-order pipeline and uncore components coupled to a timing simulator. CACTI<sup>[2]</sup> models the PPA of SRAM-based caches and DRAM.</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/mcpat_flow-ee4a98d1.png">
      <figcaption class="small center">The simulation flow provided by McPAT.</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="70%" src="/assets/mcpat_output-10446a48.png">
      <figcaption class="small center">McPAT results. Inputs: workload and microarch description. Outputs: PPA</figcaption>
    </div>
  </div>

  <div class="fragment">
  <hr>
  <div class="verysmall">
    <p class="footnote" style="margin:0;">
    [1]: Li, S., et. al., 2009. McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures. MICRO.<br />
    [2]: Muralimanohar, et al., 2009. CACTI 6.0: A tool to model large caches. HP laboratories.
    </p>
  </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: "Detailed" uArch Models - Cores</h2>

  <!-- Modeling precise microarchitectural details usually at cycle-level time-granularity -->
  <!-- Workload type - concrete binary -->

  <ul class="smallish">
    <li class="fragment">The most popular way to evaluate core microarchitectural optimizations is with a detailed execution-driven simulator. Many microarchitectural states are modeled.</li>
    <li class="fragment">Prior Work: gem5, ZSim, SST, MARSSx86, Sniper, ESESC. These simulators model the core pipeline and uncore components with cycle-level time-granularity.</li>
  </ul>

  <div class="center r-stack">
    <div class="fragment fade-in-then-out" style="display: grid; place-items: center;">
      <img width="50%" src="/assets/gem5_architecture-e0f288ad.png">
      <figcaption class="small center">The modular architecture of gem5.</figcaption>
    </div>
    <div class="fragment fade-in" style="display: grid; place-items: center;">
      <img width="80%" src="/assets/gem5_kanata_pipeline_viewer-57c75e66.png">
      <figcaption class="small center">Detailed per-instruction core pipeline visualization using Konata.</figcaption>
    </div>
  </div>
</section>

<section>
  <h2>Hardware Abstractions: RTL</h2>

  <ul>
    <li class="fragment">Register-transfer level (RTL) (e.g. Verilog) is the lowest abstraction used in pre-silicon architecture evaluation</li>
    <li class="fragment">Every bit of state and logic is explicitly modeled. RTL is the highest fidelity hardware model.</li>
    <li class="fragment">Can extract very precise power, performance, and area metrics</li>
  </ul>
</section>

<section>
  <h2>Simulator Metrics</h2>

  <p class="center fragment">Simulation techniques span the gamut on various axes</p>

  <ul class="smallish">
    <li class="fragment"><strong>Throughput</strong>
      <ul><li>How many instructions can be simulated per real second? (MIPS = millions of instructions per second)</li></ul>
    </li>
    <li class="fragment"><strong>Accuracy</strong>
      <ul><li>Do the output metrics of the simulator match those of the modeled SoC in its real environment?</li></ul>
    </li>
    <li class="fragment"><strong>Startup latency</strong>
      <ul><li>How long does it take from the moment the simulator's parameters/inputs are modified to when the first instruction is executed?</li></ul>
    </li>
    <li class="fragment"><strong>Metric diversity</strong>
      <ul>
        <li>What metrics can the simulator emit?</li>
        <li>This is tied to the hardware abstraction used</li>
      </ul>
    </li>
    <li class="fragment"><strong>Cost</strong>
      <ul>
        <li>What hardware platform does the simulator run on?</li>
        <li>How much does it cost to run a simulation?</li>
      </ul>
    </li>
  </ul>
</section>

<section>

  <!--RTL vs detailed uArch vs arch vs high-level spec

  We will restrict our scope to architectures which already have concrete implementations.
  No need to high-level analytical analysis since we're trying to speed up iteration loop, not discover new accelerator or core architectures.
  This is a separate research direction.-->
  <h2>Existing Hardware Evaluation Techniques</h2>

  <table style="width: 100%; font-size:60%; border-collapse: separate;">
    <thead><tr>
      <th></th>
      <th>Throughput</th>
      <th>Latency</th>
      <th>Accuracy</th>
      <th>Metrics</th>
      <th>Cost</th>
    </tr></thead>
    <tbody>
    <tr class="fragment">
      <td>Analytical Models</td>
      <td class="bg-green">10-1000 MIPS</td>
      <td class="bg-green">seconds</td>
      <td class="bg-red">Wildly variable</td>
      <td>PPA estimates</td>
      <td class="bg-green">Minimal</td>
    </tr>
    <tr class="fragment">
      <td>ISA Simulation</td>
      <td class="bg-green">10-100+ MIPS</td>
      <td class="bg-green">&lt;1 second</td>
      <td class="bg-red">None</td>
    </tr>
    <tr class="fragment">
      <td>μArch Perf Sim</td>
      <td class="bg-orange">100 KIPS (gem5)</td>
      <td class="bg-green">5-10 seconds</td>
      <td class="bg-orange">5-10% avg IPC error</td>
    </tr>
    <tr class="fragment">
      <td>RTL Simulation</td>
      <td class="bg-red">1-10 KIPS</td>
      <td class="bg-orange">5-10 minutes</td>
      <td class="bg-green">cycle-exact</td>
    </tr>
    <tr class="fragment">
      <td>FireSim (FPGA)</td>
      <td class="bg-green">1-50 MIPS</td>
      <td class="bg-red">2-6 hours</td>
      <td class="bg-green">cycle-exact</td>
    </tr>
    <tr class="fragment">
      <td><strong>TidalSim</strong></td>
      <td>10 MIPS</td>
      <td>&lt;1 minute</td>
      <td style="font-size: 90%">&lt;5% error, 10k intervals</td>
    </tr>
    </tbody>
  </table>

  <!--<ul style="margin-top: 1rem;" class="fragment">
    <li>Combine the strengths of ISA, μArch, and RTL simulators
      <ul><li>Multi-level simulation</li></ul>
    </li>
  </ul>-->

  uArch Perf Sim is nearly there! Can we improve its accuracy or improve its throughput to get us to the golden promise land?
</section>

<section>
  <h2>How Accurate are Performance Simulators?</h2>
  - cite paper on arch sims considered harmful
  Accuracy - discuss why this can't be really improved - need to resort to RTL for fidelity that we can trust (on PPA)
  Throughput - we can use sampling - let's discuss that
</section>

<section>
  <h2>Phase Behavior of Programs</h2>

  <div class="container">
  <div>
  <ul style="font-size:95%">
    <li class="fragment" data-fragment-index="1">Program execution traces aren’t random
      <ul class="fragment" data-fragment-index="2">
        <li>They execute the same code again-and-again</li>
        <li>Application execution traces can be split into <strong style="text-decoration:underline;">phases</strong> that exhibit similar μArch behavior</li>
      </ul>
    </li>
    <li class="fragment" data-fragment-index="4">Prior work: SimPoint
      <ul class="fragment" data-fragment-index="5">
        <li>Identify basic blocks executed in a given interval (e.g. 1M instruction intervals)</li>
        <li>Embed each interval using their ‘basic block vector’</li>
        <li>Cluster intervals using k-means</li>
      </ul>
    </li>
    <li class="fragment" data-fragment-index="6">Similar intervals → similar μArch behaviors
      <ul class="fragment" data-fragment-index="7"><li>Only execute unique intervals in low-level RTL simulation!</li></ul>
    </li>
  </ul>
  </div>
  <div class="fragment" data-fragment-index="3" style="display:grid; align-content: center; justify-items:center;">
    <img src="/assets/simpoint-gzip_phases-c68f8d72.gif" />
    <img src="/assets/simpoint-gcc_phases-2046d2b5.gif" />
  </div>
  </div>
</section>

<section>
  <h2>Prior Work</h2>

  <ul>
    <li class="fragment"><em>Sampled</em> simulation techniques have been used in μArch simulators for decades
      <ul>
        <li class="fragment">SimPoint-style sampling (interval clustering, large intervals)</li>
        <li class="fragment">SMARTs-style sampling (reservoir sampling, small intervals)</li>
        <li class="fragment">Implemented in gem5, Sniper, ZSim, SST</li>
      </ul>
    </li>
    <li class="fragment">LiveSim proposed 2-level simulation (ISA → μArch sim) for rapid iteration of μArch parameters
      <ul>
        <li>Functional warmup was used for the cache and branch predictor models</li>
      </ul>
    </li>
  </ul>
</section></section>

<section>
<section class="center">
  <h2 class="center">3. What's New: Differences from Prior Work</h2>
</section>

<section>
  <h2>Treating Simulation as a Sliding Tradeoff Between Latency, Throughput, and Accuracy</h2>
</section>

<section>
  <h2>Heterogeneous SoCs</h2>
  Accelerators and IO modeling, new embedding strategies, how to model memory interconnect traffic situations that can cause variance in accelerator performance
</section>

<section>
  <h2>Why RTL-Level Simulation?</h2>
  no need to add modeling error (unbounded) on top of sampling error (which can often be bounded or at least understood)
  the abstraction closest to the ultimate PPA
  for optimizations that involve uarch, we should simulate accurate uarch - this fidelity is required for proper dse that is properly physically constrained
</section>

<section>
  <h2>Challenges with RTL-Level Sampled Simulation</h2>
  Describe the challenges, but leave the solutions for subsequent sections
  State injection, interval subsampling, functional warmup, performance metric extraction, supporting different microarchitectures and HW parameter spaces
</section>

<section>
  <h2>Why RTL-Level Simulation Now?</h2>
  new frameworks enable RTL-level design space exploration
</section>

<section>
  <h2>What's New</h2>

  <ul>
    <li class="fragment">No prior work on ISA ↔ μArch models ↔ RTL multi-level simulation with functional warmup</li>
    <li class="fragment">No substantial work on binary-agnostic interval embeddings</li>
    <li class="fragment">No one has leveraged the special collateral (waveforms + high-fidelity performance metrics) you can only get from RTL simulation</li>
  </ul>
</section></section>

<section>
<section class="center">
  <h2>4. How (pt 1): TidalSim v1 (A Prototype Implementation)</h2>
</section>

<!--
  - Program intervals
  - Basic block embedding (show example)
  - Clustering (show example of clusters we extracted, 2D SVD projection and cluster coloring)
  - Checkpointing and snapshot taking
  - Injection into RTL-level simulation
  - Performance metric extraction
  - Extrapolation
-->

<section style="text-align: center;">
  <h2>Overview of Multi-Level Simulation Flow</h2>
  <img src="/assets/overview-cbf37909.svg" />
</section>

<section>
  <h2>Basic Block Identification</h2>

  <p class="center fragment">Basic blocks are extracted from the dynamic commit log emitted by spike</p>

  <pre class="fragment"><code data-trim data-noescape>
core   0: >>>>  memchr
core   0: 0x00000000800012f6 (0x0ff5f593) andi    a1, a1, 255
core   0: 0x00000000800012fa (0x0000962a) c.add   a2, a0
core   0: 0x00000000800012fc (0x00c51463) bne     a0, a2, pc + 8
core   0: 0x0000000080001304 (0x00054783) lbu     a5, 0(a0)
core   0: 0x0000000080001308 (0xfeb78de3) beq     a5, a1, pc - 6
  </code></pre>

  <ul>
    <li class="fragment">Control flow instructions mark the end of a basic block</li>
    <li class="fragment">Previously identified basic blocks can be split if a new entry point is found</li>
    <li class="fragment"><code>0: 0x8000_12f6 ⮕ 0x8000_12fc</code></li>
    <li class="fragment"><code>1: 0x8000_1304 ⮕ 0x8000_1308</code></li>
  </ul>
</section>

<section>
  <h2>Program Intervals</h2>

  <p class="center fragment">A execution trace is captured from ISA-level simulation</p>
  <pre class="fragment"><code data-trim data-noescape>
core   0: >>>>  memchr
core   0: 0x00000000800012f6 (0x0ff5f593) andi    a1, a1, 255
core   0: 0x00000000800012fa (0x0000962a) c.add   a2, a0
core   0: 0x00000000800012fc (0x00c51463) bne     a0, a2, pc + 8
core   0: 0x0000000080001304 (0x00054783) lbu     a5, 0(a0)
core   0: 0x0000000080001308 (0xfeb78de3) beq     a5, a1, pc - 6
core   0: 0x000000008000130c (0x00000505) c.addi  a0, 1
core   0: 0x000000008000130e (0x0000b7fd) c.j     pc - 18
core   0: 0x00000000800012fc (0x00c51463) bne     a0, a2, pc + 8
  </code></pre>
  <p class="center fragment">The trace is grouped into intervals of N instructions</p>
  <p class="center fragment">Typical N for SimPoint samples is 1M</p>
  <p class="center fragment">Typical N for SMARTs samples is 10-100k</p>
</section>

<section>
  <h2>Interval Embedding and Clustering</h2>

  <p class="center fragment">Embed each interval with the frequency it traversed every identified basic block</p>

  <table style="width: 100%; font-size:90%;" class="fragment">
    <thead><tr>
      <th>Interval index</th>
      <th>Interval length</th>
      <th>Embedding</th>
    </tr></thead>
    <tbody><tr>
      <td>n</td>
      <td>100</td>
      <td><code>[40, 50, 0, 10]</code></td>
    </tr>
    <tr>
      <td>n+1</td>
      <td>100</td>
      <td><code>[0, 50, 10, 40]</code></td>
    </tr>
    <tr>
      <td>n+2</td>
      <td>100</td>
      <td><code>[0, 20, 20, 80]</code></td>
    </tr>
    </tbody>
  </table>

  <p class="center fragment">Intervals are clustered using k-means clustering on their embeddings</p>
</section>

<section>
  <h2>Arch Snapshotting</h2>

  <p class="center fragment">For each cluster, take the sample that is closest to its centroid</p>
  <p class="center fragment">Capture arch checkpoints at the start each chosen sample</p>

  <pre class="fragment"><code data-trim data-noescape>
pc = 0x0000000080000332
priv = M
fcsr = 0x0000000000000000
mtvec = 0x8000000a00006000
...
x1 = 0x000000008000024a
x2 = 0x0000000080028fa0
...
  </code></pre>

  <p class="center fragment">An arch checkpoints = arch state + raw memory contents</p>
</section>

<section>
  <h2>RTL Simulation and Arch-State Injection</h2>

  <ul>
    <li class="fragment">Arch checkpoints are run in parallel in RTL simulation for N instructions</li>
    <li class="fragment">RTL state injection caveats
      <ul>
        <li class="fragment">Not all arch state maps 1:1 with an RTL-level register</li>
        <li class="fragment">e.g. <code>fflags</code> in <code>fcsr</code> are FP exception bits from FPU μArch state</li>
        <li class="fragment">e.g. <code>FPRs</code> in Rocket are stored in recoded 65-bit format (not IEEE floats)</li>
      </ul>
    </li>
    <li class="fragment">Performance metrics extracted from RTL simulation</li>
  </ul>

  <pre class="fragment"><code data-trim data-noescape>
cycles,instret
1219,100
125,100
126,100
123,100
114,100
250,100
113,100
  </code></pre>
</section>

<section>
  <h2>Extrapolation</h2>
  <p class="center fragment">Performance metrics for one sample in a cluster are representative of all samples in that cluster</p>
  <p class="center fragment">Extrapolate on the entire execution trace to get a full IPC trace</p>
</section>

<section>
  <h2>Functional Cache Warmup</h2>
  <div class="container">
  <div>
    <ul>
      <li class="fragment" data-fragment-index="1">Each checkpoint is run in RTL simulation with a cold cache → inaccurate IPC due to incomplete cache warming during detailed warmup</li>
      <li class="fragment" data-fragment-index="3"><em>WIP</em>: "Memory Timestamp Record"<sup>[2]</sup> based cache model and RTL cache state injection</li>
    </ul>
  </div>
  <div class="fragment" data-fragment-index="2">
    <img width="100%" src="/assets/livesim_amat_vs_warmup-cc3cc3c5.png" />
    <figcaption class="small center">AMAT Error vs # of Functional Warmup Instructions (from LiveSim<sup>[1]</sup>)</figcaption>
  </div>
  </div>

  <div class="fragment" data-fragment-index="4">
  <hr>
  <div class="verysmall">
  <p class="footnote">
  [1]: Hassani, Sina, et al. "LiveSim: Going live with microarchitecture simulation." HPCA 2016.<br/>
  [2]: Barr, Kenneth C., et al. "Accelerating multiprocessor simulation with a memory timestamp record." ISPASS 2005.</p>
  </div>
  </div>
</section>

<section>
  <h2>Clustering on Embench Benchmarks</h2>
  <img class="fragment" src="/assets/aha-mont64_clustering-e9e97518.svg" />
  <ul>
    <li class="fragment">Cluster centroids indicate which basic blocks are traversed most frequently in each cluster</li>
    <li class="fragment">We observe that most clusters capture unique traversal patterns</li>
  </ul>
</section>

<section>
  <h2>IPC Trace Prediction</h2>
  <ul>
    <li class="fragment">Montgomery multiplication from Embench (aha-mont64)</li>
    <li class="fragment"><code>N=1000</code>, <code>C=12</code></li>
    <li class="fragment">Full RTL sim takes 10 minutes, TidalSim runs in 10 seconds</li>
    <li class="fragment">IPC is correlated (mean error &lt;5%) and mild correlation between distance and error</li>
  </ul>
  <img class="fragment" src="/assets/aha-mont64_results-9a84d301.svg" />
</section></section>

<section>
<section class="center">
  <h2>5. How (pt 2): TidalSim v2</h2>
  <ol>
    <li>Not general or streaming
      <ul>
        <li>Hardcoded Simpoint-style sampled simulation</li>
        <li>Requires multiple passes over the commit trace / multiple runs of spike</li>
      </ul>
    </li>
    <li>Inaccurate at modeling asynchronous / timing-aware events (timer/external interrupts)</li>
    <li>Hardcoded for a single RTL design point</li>
    <li>Functional warmup models aren't validated against RTL</li>
    <li>Not warming up all necessary uarch state + resolving ambiguity in restoring arch state</li>
    <li>Interval embeddings are binary-aware (not portable) and not microarchitecture-aware (higher liklihood for errors)</li>
    <li>Modeling of I/O (off-chip communication, polling, interrupts) will be inaccurate due to uniform treatment of any memory access</li>
    <li>Interaction with core-coupled accelerators isn't properly embedded or checkpointable</li>
  </ol>
</section>

<section>
  <h2>1. Generalizing the Spectrum of Simulation</h2>
  generalization + streaming (no preprocessing step required)
</section>

<section>
  <h2>2. Modeling Timing-Aware Events (Dynamic Simulation)</h2>
  going from one-direction simulation to dynamically changing simulators up and down the stack during execution
</section>

<section>
  <h2>3. Leveraging Chisel for State Injection</h2>
</section>

<section>
  <h2>4. Validating Functional Warmup Models</h2>
</section>

<section>
  <h2>5. Long-Lived uArch State Identification</h2>
</section>

<section>
  <h2>5. Resolving Ambiguity in Forcing Arch State</h2>
</section>

<section>
  <h2>6. Better Interval Embeddings</h2>
</section>

<section>
  <h2>7. Modeling I/O</h2>
</section>

<section>
  <h2>8. Sampled Simulation with Accelerators</h2>
</section></section>

<section>
<section class="center">
  <h2>6. Case Studies / Applications</h2>
</section>

<section>
  <h2>Performance and Power Evaluation</h2>
  <ul>
    <li class="fragment">Fast, low-latency evaluation of HW parameters on long running workloads
    <ul>
      <li>Cache sizing between L1d vs L1i</li>
      <li>Balancing of 2-level cache hierarchies</li>
      <li>Unified vs separate i/d L2 caches</li>
    </ul>
    </li>
    <li class="fragment">Trace extraction for power model construction
    <ul>
      <li>Currently power macromodels are built + trained only on workloads that can run in RTL simulation</li>
      <li>TidalSim enables extraction of unique, short traces from full workloads</li>
      <li>Potential to improve signal selection and uncover holes in training datasets</li>
    </ul>
    </li>
  </ul>
</section>

<section>
  <h2>Issues with HW Fuzzer Evaluations</h2>
  <ul>
    <li class="fragment"><em>Last time</em>: discussed deficiencies in existing HW fuzzing evaluations due to bad success/feedback metrics
    <ul>
      <li class="fragment">Structural coverage is too easy to hit</li>
      <li class="fragment">Time to rediscover old bugs is too biased and forces us to use old RTL</li>
    </ul>
    </li>
    <li class="fragment">Bad metrics ⮕ dubious conclusions
    <ul>
      <li>We should save &gt;50% of mutated stimuli (vs &lt;1% for SW fuzzers)</li>
      <li>RTL-level feedback is useless for hitting bugs or improving coverage (vs SW fuzzers making no progress without feedback)</li>
    </ul>
    </li>
  </ul>
  <p class="center fragment">Can we synthesize metrics that lead to reasonable HW fuzzer evaluations?</p>
</section>

<section>
  <h2>Coverpoint Synthesis</h2>
  <ul>
    <li class="fragment"><em>Specification mining</em> takes waveforms of an RTL design and synthesizes properties involving 2+ signals that are unfalsified on all traces</li>
    <li class="fragment">Coverpoint synthesis is an alternative take on spec mining where we synthesize μArch properties that we want to see more of</li>
    <li class="fragment">This technique is far more effective if we have <em>many unique, realistic traces</em>
      <ul>
        <li class="fragment">Leverage interval clustering and sampled RTL simulation</li>
      </ul>
    </li>
  </ul>
</section>

<section>
  <h2>Bootstrapping Fuzzing</h2>
  <ul>
    <li class="fragment">Most HW fuzzers start from reset and run a binary on the SoC to hit some objective</li>
    <li class="fragment">Interesting objectives are harder to hit from reset vs from the middle of a workload
    <ul><li>e.g. post-OS boot, in the middle of an application</li></ul>
    </li>
    <li class="fragment">Arch and μArch checkpoints from TidalSim guarantee reachability and provides starting points for HW fuzzers</li>
  </ul>
</section></section>

<section>
  <section class="center">
    <h2>7. Thesis Outline</h2>
  </section>

  <section>
    <h2>Outline</h2>
  </section>
</section>


<section data-visibility="hidden">
  <h2>Problem Overview</h2>

  <p class="center fragment">Fast RTL-level μArch simulation and performance metric / interesting trace extraction</p>
  <p class="center fragment"><em><strong>enables</strong></em></p>
  <p class="center fragment">Rapid RTL iteration with performance, power modeling, and verification evaluation on real workloads</p>
  <hr class="fragment">
  <p class="center fragment">How can we achieve high throughput, high fidelity, low latency μArch simulation with RTL-level interesting trace extraction?</p>
</section>

<section data-visibility="hidden">
  <h2>Motivation</h2>

  <ul>
    <li class="fragment">We want fast design iteration and evaluation of PPA + verification given real workloads
    <!--Fast design iteration and evaluation of PPA + verification requires stimulus that's representative and comprehensive wrt real workloads (execution fragments)-->
    </li>
    <li class="fragment">The enablers are: <em>fast and accurate μArch simulation</em> and a way to identify <em>unique execution fragments</em>
      <ul>
        <li class="fragment"><em>Performance estimation:</em> Performance metric extraction from fast RTL simulation</li>
        <li class="fragment"><em>Power macromodeling:</em> Extraction of interesting program traces for clustering/training</li>
        <li class="fragment"><em>Verification:</em> Extraction of traces for coverpoint/specification synthesis + state seeding for fuzzing</li>
      </ul>
    </li>
  </ul>
</section>

<section data-visibility="hidden">
  <h2>Pre-Silicon Microarchitecture Simulation</h2>

  <ul>
    <li class="fragment"><em>Performance estimation:</em> Impact of μArch optimizations / HW parameters on real workloads</li>
    <li class="fragment"><em>Power macromodeling:</em> Identification of important netlist nodes in power model + traces for training</li>
    <li class="fragment"><em>Verification:</em> Bootstrapping fuzzing loops + coverpoint synthesis</li>
  </ul>
</section>

<section data-visibility="hidden">
  <section>
    <h2>Performance Optimizations</h2>
    <ul>
      <li class="fragment">Currently two runs of the binary through spike are needed
      <ul>
        <li>One to get a commit log for basic block extraction, embedding, and clustering</li>
        <li>One more to dump arch checkpoints for chosen samples</li>
      </ul>
      </li>
      <li class="fragment">We can take regular checkpoints during the first execution to make arch checkpoint collection fast</li>
    </ul>
  </section>

  <section>
    <h2>Validation of State Injection</h2>
    <ul>
      <li class="fragment">There is no arch state comparison at the end of a checkpoint run in RTL simulation</li>
      <li class="fragment">We will standardize a arch state schema and dump a reference state from spike to check against</li>
    </ul>
  </section>

  <section>
    <h2>Handling Large Interval Lengths</h2>
    <ul>
      <li class="fragment">Real programs will use large intervals (1-10M instructions)</li>
      <li class="fragment">Selected intervals can't be run in their entirety in RTL simulation</li>
      <li class="fragment">Sub-sampling intervals with random sampling is required</li>
    </ul>
  </section>
</section>

<section>
  <h2>Conclusion</h2>

  <div class="container" style="grid-template-columns: 1fr 1.4fr;">
  <div>
  <ul>
    <li class="fragment">We want rapid iteration wrt PPA evaluation and verification objectives</li>
    <li class="fragment">We need fast RTL-level simulation with trace extraction</li>
    <li class="fragment">We propose <strong>TidalSim</strong>, a multi-level simulation methodology to enable rapid HW iteration</li>
  </ul>
  </div>
  <div style="display:grid; align-content: center;">
    <img src="/assets/overview-cbf37909.svg" />
  </div>
  </div>

  <p class="center fragment"><a href="https://github.com/euphoric-hardware/tidalsim">TidalSim (github.com/euphoric-hardware/tidalsim)</a></p>
</section>

        </div>
    </div>

    
  </body>
</html>